{
  "hash": "cfa2a4d4708d8f11e3db461d469de705",
  "result": {
    "markdown": "# Example Model 4: Logistic regression with censored predictors\n\n\n\n\n\nFor the next example model we have enough background knowledge to implement\na model for a problem that my group has been trying to tackle recently, and\nthat is somewhat common with the type of data that I work with. Suppose we want\nto test the efficacy of a novel vaccine candidate in a clinical trial.\n\nTypically, these vaccines have **immunological correlates of protection**,\nsome value we can measure that gives a general idea of how strong a person's\nimmune response was, and correlates with their probability of getting a disease.\nOne of the most common types of these measurements are antibody titers, where\ntypically a high antibody titer is protective and corresponds to a lower\nprobability of disease. If we have a clinical trial where we record if\npatients get the disease (after challenge or after a sufficiently long\nfollowup period, for this example the details are not too important as long\nas we assume the infection status is measured accurately), we can model how\nthese measurements are related to protection via **logistic regression**.\n\n## Model with one patient group\n\nFor the first model, we'll consider a simpler case where we only have one\ngroup of patients. This model would be appropriate for, e.g., an observational\nstudy where all patients are given the vaccine of interest.\n\nThe data generating model is as follows:\n\n$$\n\\begin{align*}\ny_i &\\sim \\text{Bernoulli}\\left(p\\right) \\\\\n\\mathrm{logit}(p) &= \\alpha + \\beta \\cdot x_i\n\\end{align*}\n$$\nwhere $y_i$ is a binary outcome where 1 indicates infection and 0 indicates\nno infection, and $x_i$ is our antibody titer. However, the specific problem\nwe deal with in practice is that these antibody titers tend to have lower\nlimits of detection. Thus, we need to add an observation model to our\ndata generating process to reflect the incomplete observations we obtain of $x$.\n\n$$\n\\begin{align*}\ny_i &\\sim \\text{Bernoulli}\\left(p_i\\right) \\\\\n\\mathrm{logit}(p_i) &= \\alpha + \\beta \\cdot x^*_i \\\\\nx_i^* &\\sim \\mathrm{Normal}\\left(\\mu_x, \\sigma^2_x\\right) \\\\\nx_i &= \\begin{cases}\n\\frac{1}{2}\\mathrm{LoD}, & x^*_i < \\mathrm{LoD} \\\\\nx^*_i, & x^*_i \\geq \\mathrm{LoD}\n\\end{cases} \\\\\n\\end{align*}\n$$\nHere, we assume that we work with the $x$ variable on the log scale at all times,\\\nmostly cause it's annoying and confusing to write out all the logs every time,\nso we could also write\n$$x_i^* = \\mathrm{log} \\left(z^*_i\\right)$$\nand say $z^*_i$ is the actual latent un-logged titer.\n\nNow that we have the data generating process written out, we can simulate\nsome example data. Note that in this example, we can interpret $\\alpha$ as the\nlog-odds of infection if a person were to have no antibodies. For example,\nif we assume that this probability is $50\\%$ we would apply the logit\ntransformation to get that $\\alpha = 0$. However, let's assume that the\ninoculum dose is quite high and during our subject selection process we've\nincluded anyone who might have a genetic resistance to the disease (i.e.,\nFUT2- individuals for norovirus). So let's say if a person has zero antibodies,\ntheir probably of getting sick should be $90\\%$. Then, $\\log(0.9 / 0.1) \\approx 2.2$.\n\nWe then want our true $\\beta$ value to be negative, indicating that\nas the number of antibodies rise, the log-odds of infection decrease. We can\ninterpret $\\beta$ as the change in the log-odds ratio associated with a\none-unit change in antibody titer -- the nonlinearity here makes it a bit\nmore difficult to interpret this effect. We can, however, intercept $\\exp(\\beta)$ as the odds ratio between individuals with titer $x_i + 1$ and \nindividuals with titer $x_i$. This corresponds to a nonlinear change in risk\nthat depends on the value of $x_i$. However, if we want the odds of infection\nto halve for each 1 unit increase in antibody titer, we would set $\\beta = -\\log(2) \\approx -0.7$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(134125)\nsim_parms <- list(\n\tn = 110,\n\talpha = 2.2,\n\tbeta = -1.37,\n\tmu_x = 2,\n\tsigma_x = 2,\n\tLoD = 0\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninv_logit <- function(x) {return(1 / (1 + exp(-x)))}\n\nsim_one_group <- function(n, alpha, beta, mu_x, sigma_x, LoD) {\n\tout <- tibble::tibble(\n\t\tx_star = rnorm(n, mu_x, sigma_x),\n\t\tx = ifelse(x_star < LoD, 0.5 * LoD, x_star),\n\t\tp = inv_logit(alpha + beta * x_star),\n\t\ty = rbinom(n, size = 1, prob = p)\n\t)\n}\n\nsim_data <- do.call(sim_one_group, sim_parms)\n```\n:::\n\n\nOf course visualizing the relationship between a binary outcome and a\ncontinuous predictor is in some sense more complex than visualizing the\nrelationship between a continuous outcome and a continuous predictor.\n\nFirst, let's look at how the distribution of the predictor variable changes\nif we condition on the outcome.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_data |>\n\ttidyr::pivot_longer(cols = c(x, x_star)) |>\n\tdplyr::mutate(\n\t\tyf = factor(\n\t\t\ty,\n\t\t\tlevels = c(0, 1),\n\t\t\tlabels = c(\"Not infected\", \"Infected\")\n\t\t),\n\t\tname = factor(\n\t\t\tname,\n\t\t\tlevels = c(\"x_star\", \"x\"),\n\t\t\tlabels = c(\"Latent variable\", \"Observed variable\")\n\t\t)\n\t) |>\n\tggplot() +\n\taes(x = value, fill = yf) +\n\tgeom_vline(\n\t\txintercept = 0,\n\t\tlinetype = \"dashed\",\n\t\tcolor = \"black\",\n\t\tlinewidth = 1\n\t) +\n\tgeom_histogram(\n\t\tbinwidth = 0.5, boundary = 0, closed = \"left\",\n\t\tposition = \"identity\", alpha = 0.6,\n\t\tcolor = \"black\"\n\t) +\n\tscale_x_continuous(\n\t\tname = \"Simulated log titer\",\n\t\tbreaks = scales::breaks_pretty()\n\t) +\n\tscale_y_continuous(breaks = scales::breaks_pretty()) +\n\tscale_fill_brewer(palette = \"Dark2\", name = NULL) +\n\tfacet_wrap(facets = vars(name))\n```\n\n::: {.cell-output-display}\n![](Ex4-Infection-Outcome-with-Censored-Predictor_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nEssentially everything below our lower threshold gets bumped up, which\nwill make the summary statistics of the distribution more similar between\ngroups for the observed titer values than they would have been for the latent\ntiter values. However, we can still see a large difference.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninterp <-\n\ttibble::tibble(\n\t\tvalue = seq(-2, 6, 0.1),\n\t\tp = inv_logit(sim_parms$alpha + sim_parms$beta * value)\n\t)\n\ninterp2 <-\n\tdplyr::bind_rows(\n\t\t\"Latent variable\" = interp,\n\t\t\"Observed variable\" = interp,\n\t\t.id = \"name\"\n\t)\n\nlab1 <- latex2exp::TeX(r\"($Pr(y_{i} = 1 \\ | \\ x_{i})$)\")\n\nsim_data |>\n\ttidyr::pivot_longer(cols = c(x, x_star)) |>\n\tdplyr::mutate(\n\t\tyf = factor(\n\t\t\ty,\n\t\t\tlevels = c(0, 1),\n\t\t\tlabels = c(\"Not infected\", \"Infected\")\n\t\t),\n\t\tname = factor(\n\t\t\tname,\n\t\t\tlevels = c(\"x_star\", \"x\"),\n\t\t\tlabels = c(\"Latent variable\", \"Observed variable\")\n\t\t)\n\t) |>\n\tggplot() +\n\taes(x = value, color = name) +\n\tgeom_line(\n\t\tdata = interp2, aes(y = p), color = \"darkgray\", linetype = 2, linewidth = 1\n\t) +\n\tgeom_point(\n\t\taes(y = y), size = 3, alpha = 0.5,\n\t\tposition = position_jitter(width = 0, height = 0.05, seed = 370)\n\t) +\n\tscale_x_continuous(\n\t\tname = \"Simulated log titer\",\n\t\tbreaks = scales::breaks_pretty()\n\t) +\n\tscale_y_continuous(\n\t\tname = lab1,\n\t\tbreaks = scales::breaks_pretty()\n\t) +\n\tscale_color_brewer(palette = \"Accent\", name = NULL) +\n\tfacet_wrap(facets = vars(name))\n```\n\n::: {.cell-output-display}\n![](Ex4-Infection-Outcome-with-Censored-Predictor_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_list <-\n\tsim_data |>\n\tdplyr::mutate(x_l = sim_parms$LoD) |>\n\tdplyr::select(x, x_l, y) |>\n\tas.list()\n\ndata_list$N <- sim_parms$n\n\nstr(data_list)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 4\n $ x  : num [1:110] 0.123 1.872 0.932 1.865 1.925 ...\n $ x_l: num [1:110] 0 0 0 0 0 0 0 0 0 0 ...\n $ y  : int [1:110] 1 0 1 0 0 0 1 0 0 0 ...\n $ N  : num 110\n```\n:::\n:::\n\n\n````{.stan, include = \"Ex4a.stan\"}\n\n```\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- cmdstanr::cmdstan_model(here::here(\"Ex4a.stan\"), compile = FALSE)\nmod$compile(force_recompile = TRUE, pedantic = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nIn file included from stan/lib/stan_math/lib/boost_1.78.0/boost/multi_array/multi_array_ref.hpp:32,\n                 from stan/lib/stan_math/lib/boost_1.78.0/boost/multi_array.hpp:34,\n                 from stan/lib/stan_math/lib/boost_1.78.0/boost/numeric/odeint/algebra/multi_array_algebra.hpp:22,\n                 from stan/lib/stan_math/lib/boost_1.78.0/boost/numeric/odeint.hpp:63,\n                 from stan/lib/stan_math/stan/math/prim/functor/ode_rk45.hpp:9,\n                 from stan/lib/stan_math/stan/math/prim/functor/integrate_ode_rk45.hpp:6,\n                 from stan/lib/stan_math/stan/math/prim/functor.hpp:15,\n                 from stan/lib/stan_math/stan/math/rev/fun.hpp:198,\n                 from stan/lib/stan_math/stan/math/rev.hpp:10,\n                 from stan/lib/stan_math/stan/math.hpp:19,\n                 from stan/src/stan/model/model_header.hpp:4,\n                 from C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f10756f6390.hpp:2:\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:180:45: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  180 |         : public boost::functional::detail::unary_function<typename unary_traits<Predicate>::argument_type,bool>\n      |                                             ^~~~~~~~~~~~~~\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nIn file included from C:/rtools43/ucrt64/include/c++/13.2.0/string:49,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/bits/locale_classes.h:40,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/bits/ios_base.h:41,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/ios:44,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/istream:40,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/sstream:40,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/complex:45,\n                 from stan/lib/stan_math/lib/eigen_3.4.0/Eigen/Core:50,\n                 from stan/lib/stan_math/lib/eigen_3.4.0/Eigen/Dense:1,\n                 from stan/lib/stan_math/stan/math/prim/fun/Eigen.hpp:22,\n                 from stan/lib/stan_math/stan/math/rev.hpp:4:\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:214:45: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  214 |         : public boost::functional::detail::binary_function<\n      |                                             ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:252:45: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  252 |         : public boost::functional::detail::unary_function<\n      |                                             ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:299:45: warning: 'template<cl\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nass _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  299 |         : public boost::functional::detail::unary_function<\n      |                                             ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:345:57: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  345 |     class mem_fun_t : public boost::functional::detail::unary_function<T*, S>\n      |                                                         ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:361:58: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  361 |     class mem_fun1_t : public boost::functional::detail::binary_function<T*, A, S>\n      |                                                          ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:377:63: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  377 |     class const_mem_fun_t : public boost::functional::detail::unary_function<const T*, S>\n      |                                                               ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:393:64: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  393 |     class const_mem_fun1_t : public boost::functional::detail::binary_function<const T*, A, S>\n      |                                                                ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\ndeclared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:438:61: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  438 |     class mem_fun_ref_t : public boost::functional::detail::unary_function<T&, S>\n      |                                                             ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:454:62: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  454 |     class mem_fun1_ref_t : public boost::functional::detail::binary_function<T&, A, S>\n      |                                                              ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:470:67: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  470 |     class const_mem_fun_ref_t : public boost::functional::detail::unary_function<const T&, S>\n      |                                                                   ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:487:68: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  487 |     class const_mem_fun1_ref_t : public boost::functional::detail::binary_function<const T&, A, S>\n      |                                        \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                            ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:533:73: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  533 |     class pointer_to_unary_function : public boost::functional::detail::unary_function<Arg,Result>\n      |                                                                         ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:557:74: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  557 |     class pointer_to_binary_function : public boost::functional::detail::binary_function<Arg1,Arg2,Result>\n      |                                                                          ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nIn file included from stan/lib/stan_math/stan/math/prim/prob/von_mises_lccdf.hpp:5,\n                 from stan/lib/stan_math/stan/math/prim/prob/von_mises_ccdf_log.hpp:4,\n                 from stan/lib/stan_math/stan/math/prim/prob.hpp:356,\n                 from stan/lib/stan_math/stan/math/prim.hpp:16,\n                 from stan/lib/stan_math/stan/math/rev.hpp:14:\nstan/lib/stan_math/stan/math/prim/prob/von_mises_cdf.hpp: In function 'stan::return_type_t<T_x, T_sigma, T_l> stan::math::von_mises_cdf(const T_x&, const T_mu&, const T_k&)':\nstan/lib/stan_math/stan/math/prim/prob/von_mises_cdf.hpp:194: note: '-Wmisleading-indentation' is disabled from this point onwards, since column-tracking was disabled due to the size of the code/headers\n  194 |       if (cdf_n < 0.0)\n      | \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nstan/lib/stan_math/stan/math/prim/prob/von_mises_cdf.hpp:194: note: adding '-flarge-source-files' will allow for more column-tracking support, at the expense of compilation time and memory\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nIn file included from stan/src/stan/model/model_header.hpp:11:\nstan/src/stan/model/model_base_crtp.hpp: At global scope:\nstan/src/stan/model/model_base_crtp.hpp:198: warning: 'void stan::model::model_base_crtp<M>::write_array(boost::random::ecuyer1988&, std::vector<double, std::allocator<double> >&, std::vector<int>&, std::vector<double, std::allocator<double> >&, bool, bool, std::ostream*) const [with M = Ex4a_model_namespace::Ex4a_model; boost::random::ecuyer1988 = boost::random::additive_combine_engine<boost::random::linear_congruential_engine<unsigned int, 40014, 0, 2147483563>, boost::random::linear_congruential_engine<unsigned int, 40692, 0, 2147483399> >; std::ostream = std::basic_ostream<char>]' was hidden [-Woverloaded-virtual=]\n  198 |   void write_array(boost::ecuyer1988& rng, std::vector<double>& theta,\n      | \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nC:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f10756f6390.hpp:392: note:   by 'Ex4a_model_namespace::Ex4a_model::write_array'\n  392 |   write_array(RNG& base_rng, std::vector<double>& params_r, std::vector<int>&\n      | \nstan/src/stan/model/model_base_crtp.hpp:136: warning: 'void stan::model::model_base_crtp<M>::write_array(boost::random::ecuyer1988&, Eigen::VectorXd&, Eigen::VectorXd&, bool, bool, std::ostream*) const [with M = Ex4a_model_namespace::Ex4a_model; boost::random::ecuyer1988 = boost::random::additive_combine_engine<boost::random::linear_congruential_engine<unsigned int, 40014, 0, 2147483563>, boost::random::linear_congruential_engine<unsigned int, 40692, 0, 2147483399> >; Eigen::VectorXd = Eigen::Matrix<double, -1, 1>; std::ostream = std::basic_ostream<char>]' was hidden [-Woverloaded-virtual=]\n  136 |   void write_array(boost::ecuyer1988& rng, Eigen::VectorXd& theta,\n      | \nC:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f10756f6390.hpp:392: note:   by 'Ex4a_model_namespace::Ex4a_model::write_array'\n  392 |   write_array(RNG& base_rng, std::vector<double>& params_r, std::vector<int>&\n      | \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- mod$sample(\n\tdata_list,\n\tseed = 25452345,\n\tparallel_chains = 4,\n\titer_warmup = 500,\n\titer_sampling = 2500,\n\tshow_messages = T\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 3000 [  0%]  (Warmup) \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in 'C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f10756f6390.stan', line 59, column 3 to column 32)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nChain 1 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 1 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 1 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 1 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 1 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 1 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 1 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 1 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 1 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 1 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 1 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 1 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 1 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 1 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 1 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 1 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 1 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 1 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 1 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 1 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 1 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 1 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 1 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 1 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 1 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 1 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 1 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 1 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 1 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 2 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 2 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 2 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 2 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 2 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 2 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 2 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 2 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 2 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 2 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 2 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 2 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 2 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 2 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 2 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 2 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 2 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 2 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 2 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 2 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 2 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 2 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 2 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 2 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 2 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 2 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 2 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 3 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 3 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 3 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 3 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 3 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 3 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 3 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 3 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 3 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 3 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 3 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 3 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 3 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 3 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 3 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 3 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 3 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 3 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 3 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 3 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 3 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 3 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 3 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 3 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 3 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 3 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 3 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 3 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 3 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 3 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 3 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 4 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 4 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 4 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 4 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 4 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 4 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 4 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 4 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 4 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 4 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 4 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 4 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 4 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 4 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 4 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 4 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 4 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 4 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 4 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 4 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 4 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 4 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 4 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 4 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 4 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 4 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 4 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 4 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 4 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\nChain 3 finished in 0.4 seconds.\nChain 4 finished in 0.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.9 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit$cmdstan_diagnose()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing csv files: C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/Ex4a-202310312225-1-879365.csv, C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/Ex4a-202310312225-2-879365.csv, C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/Ex4a-202310312225-3-879365.csv, C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/Ex4a-202310312225-4-879365.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n```\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 10\n  variable    mean  median    sd   mad      q5      q95  rhat ess_bulk ess_tail\n  <chr>      <num>   <num> <num> <num>   <num>    <num> <num>    <num>    <num>\n1 lp__     -190.   -189.   1.44  1.21  -192.   -188.     1.00    4408.    5589.\n2 alpha       1.91    1.90 0.411 0.416    1.26    2.60   1.00    5508.    5501.\n3 beta       -1.23   -1.22 0.226 0.226   -1.62   -0.881  1.00    5323.    5512.\n4 mu_x        1.84    1.85 0.234 0.231    1.45    2.22   1.00    8886.    6064.\n5 sigma_x     2.32    2.31 0.177 0.174    2.05    2.63   1.00    9161.    6999.\n```\n:::\n:::\n\n\n\n## Effect of vaccine\n\nOf course, a more interesting question is when we have $k$ different\ntreatment groups. These groups could be vaccine and placebo, like the example\nthat motivated this project, or they could be multiple different vaccine\ncandidates, doses, etc. So we now need to incorporate the effect of the\ntreatment into the model. However, we know that the treatment will have a\n**direct effect on $x$**, the antibody titers, and we can add a **direct effect\non $y$** to represent the combined effect of the vaccine on other facets of the\nimmune system (e.g. cell-mediated responses) which explain variations in\ninfection risk that are not due to antibodies.\n\nIn this framework, **$x$ becomes a mediator of the relationship between $t$, the\ntreatment, and $y$**. For simplicity, we model the effect of $t$ on $x$, and the\neffect of $t$ and $x$ jointly on $y$, both as linear functions of the\npredictors. Specifically, the data generating model is given as follows.\n\n$$\n\\begin{align*}\ny_i &\\sim \\text{Bernoulli}\\left(p_i\\right) \\\\\n\\mathrm{logit}(p_i) &= \\beta_{1, T[i]} + \\beta_{2, T[i]} \\cdot x^*_i \\\\\n\\log\\left(x_i^*\\right) &\\sim \\mathrm{Normal}\\left(\\mu_x, \\sigma^2_x\\right) \\\\\n\\mu_x &= \\alpha_{T[i]} \\\\\nx_i &= \\begin{cases}\n\\frac{1}{2}\\mathrm{LoD}, & x^*_i < \\mathrm{LoD} \\\\\nx^*_i, & x^*_i \\geq \\mathrm{LoD}\n\\end{cases} \\\\\nT[i] &= \\begin{cases}\n1, & \\text{individual } i \\text{ is in the placebo group} \\\\\n2, & \\text{individual } i \\text{ is in the vaccine group}\n\\end{cases}\n\\end{align*}\n$$\n\nGiven the generative model, we can simulate data which follow our assumptions.\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(341341)\n# Some parameters are commented out because I originally had a global\n# intercept for mu and for p, but then the intercept parameters are\n# nonidentifiable under index coding as written.\nsim2_parms <- list(\n\tn = 116,\n\t#a0 = 2,\n\ta1 = c(2.5, 4),\n\t#b0 = 1.5,\n\tb1 = c(1.7, 2.2),\n\tb2 = c(-0.67, -1.37),\n\tsigma_x = 1.5,\n\tLoD = 3,\n\tlatent = TRUE\n)\nsim_two_groups <- function(n, b1, b2, a1, sigma_x, LoD,\n\t\t\t\t\t\t\t\t\t\t\t\t\t latent = TRUE) {\n\tout <- tibble::tibble(\n\t\t# Randomly assign each individual to 1 (placebo) or 2 (vaccine)\n\t\tt = rbinom(n, size = 1, prob = 0.5) + 1,\n\t\tmu = a1[t],\n\t\tx_star = rnorm(n, mu, sigma_x),\n\t\tx = dplyr::if_else(x_star < LoD, 0.5 * LoD, x_star),\n\t\tp = inv_logit(b1[t] + b2[t] * x_star),\n\t\ty = rbinom(n, 1, prob = p)\n\t)\n\t\n\t# If the arg 'latent' is specified as anything other than FALSE, return the\n\t# latent variables that we don't observe. Otherwise return only (X, y).\n\tif (isFALSE(latent)) {\n\t\tout <- out |> dplyr::select(t, x, y)\n\t}\n\t\n\treturn(out)\n}\nsim_data_4b <- do.call(sim_two_groups, sim2_parms)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_dat <-\n\tsim_data_4b |>\n\tdplyr::mutate(\n\t\tt = factor(\n\t\t\tt,\n\t\t\tlevels = c(2, 1),\n\t\t\tlabels = c(\"Vaccine\", \"Placebo\")\n\t\t),\n\t\ty = factor(\n\t\t\ty,\n\t\t\tlevels = c(1, 0),\n\t\t\tlabels = c(\"Infected\", \"Not infected\")\n\t\t)\n\t)\ntab_dat |>\n\tgtsummary::tbl_cross(\n\t\trow = t, col = y,\n\t\tlabel = list(t ~ \"Treatment\", y ~ \"Outcome\")\n\t)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"afdipughoz\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#afdipughoz table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#afdipughoz thead, #afdipughoz tbody, #afdipughoz tfoot, #afdipughoz tr, #afdipughoz td, #afdipughoz th {\n  border-style: none;\n}\n\n#afdipughoz p {\n  margin: 0;\n  padding: 0;\n}\n\n#afdipughoz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#afdipughoz .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#afdipughoz .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#afdipughoz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#afdipughoz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#afdipughoz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#afdipughoz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#afdipughoz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#afdipughoz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#afdipughoz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#afdipughoz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#afdipughoz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#afdipughoz .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#afdipughoz .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#afdipughoz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#afdipughoz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#afdipughoz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#afdipughoz .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#afdipughoz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#afdipughoz .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#afdipughoz .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#afdipughoz .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#afdipughoz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#afdipughoz .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#afdipughoz .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#afdipughoz .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#afdipughoz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#afdipughoz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#afdipughoz .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#afdipughoz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#afdipughoz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#afdipughoz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#afdipughoz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#afdipughoz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#afdipughoz .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#afdipughoz .gt_left {\n  text-align: left;\n}\n\n#afdipughoz .gt_center {\n  text-align: center;\n}\n\n#afdipughoz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#afdipughoz .gt_font_normal {\n  font-weight: normal;\n}\n\n#afdipughoz .gt_font_bold {\n  font-weight: bold;\n}\n\n#afdipughoz .gt_font_italic {\n  font-style: italic;\n}\n\n#afdipughoz .gt_super {\n  font-size: 65%;\n}\n\n#afdipughoz .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#afdipughoz .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#afdipughoz .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#afdipughoz .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#afdipughoz .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#afdipughoz .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#afdipughoz .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings gt_spanner_row\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Outcome\">\n        <span class=\"gt_column_spanner\">Outcome</span>\n      </th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"Total\">Total</th>\n    </tr>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Infected\">Infected</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Not infected\">Not infected</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Treatment</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\"><br /></td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\"><br /></td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">    Vaccine</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">5</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">49</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">54</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">    Placebo</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">28</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">34</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">62</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Total</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">33</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">83</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">116</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\nBecause the data are from a (hypothetical) clinical trial, the typical\nepidemiological approach to data analysis, if we do not care about the effect\nof the mediator $x$ would be to calculate the risk ratio.\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- table(tab_dat$t, tab_dat$y, dnn = c(\"Treatment\", \"Outcome\"))\nepiR_out <- epiR::epi.2by2(\n\ttab,\n\tmethod = \"cohort.count\"\n)\nepiR_out\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Outcome +    Outcome -      Total                 Inc risk *\nExposed +            5           49         54       9.26 (3.08 to 20.30)\nExposed -           28           34         62     45.16 (32.48 to 58.32)\nTotal               33           83        116     28.45 (20.46 to 37.57)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nInc risk ratio                                 0.21 (0.09, 0.49)\nInc odds ratio                                 0.12 (0.04, 0.35)\nAttrib risk in the exposed *                   -35.90 (-50.50, -21.30)\nAttrib fraction in the exposed (%)            -387.74 (-1074.55, -102.54)\nAttrib risk in the population *                -16.71 (-31.57, -1.85)\nAttrib fraction in the population (%)         -58.75 (-89.23, -33.18)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 18.276 Pr>chi2 = <0.001\nFisher exact test that OR = 1: Pr>chi2 = <0.001\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# This one takes the variables in the opposite direction so easier to do it\n# this way\nepiDisplay::csi(\n\tcaseexp = tab[[1]],\n\tcontrolex = tab[[3]],\n\tcasenonex = tab[[2]],\n\tcontrolnonex = tab[[4]]\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n          Exposure\nOutcome    Non-exposed Exposed Total\n  Negative 34          49      83   \n  Positive 28          5       33   \n  Total    62          54      116  \n                                    \n           Rne         Re      Rt   \n  Risk     0.45        0.09    0.28 \n                                         Estimate Lower95ci Upper95ci\n Risk difference (Re - Rne)              -0.36    -0.5      -0.2     \n Risk ratio                              0.21     0.1       0.45     \n Protective efficacy =(Rne-Re)/Rne*100   79.5     55.46     90.1     \n   or percent of risk reduced                                        \n Number needed to treat (NNT)            2.79     2         4.99     \n   or -1/(risk difference)                                           \n```\n:::\n:::\n\nSo if we didn't care about the effect of $x$ at all, we would conclude that the\nvaccine appears to be protective with a RR of $`r\nround(epiR_out$massoc.summary[[1, 2]], 2)`$ and a 95% CI of $\\left(`r\nround(epiR_out$massoc.summary[[1, 3]], 2) - round(epiR_out$massoc.summary[[1,\n4]], 2)`\\right)$. **Note that this analysis is marginal to the censored $x_i$\nvalues, and since the data generating process for $y_i$ relies on the latent\n$x^*_i$ values, this analysis should not be biased by the censoring process.**\n\nHowever, in our study we specifically want to know how\nmuch of the lower risk is explained by the antibody titer, and how much is not.\nThis analysis is more complicated, and requires us to use a regression model.\nFortunately we know the data generating process, so writing the Stan code\nfor an accurate model is not too hard.\n\n<!-- NEED TO ADD HIDING CONTAINER -->\n````{.stan, include = \"Ex4b.stan\"}\n\n```\n\n::: {.cell}\n\n```{.r .cell-code}\npth <- here::here(\"Ex4b.stan\")\nmod4b <- cmdstanr::cmdstan_model(pth, compile = F)\nmod4b$compile(pedantic = TRUE, force_recompile = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nIn file included from stan/lib/stan_math/lib/boost_1.78.0/boost/multi_array/multi_array_ref.hpp:32,\n                 from stan/lib/stan_math/lib/boost_1.78.0/boost/multi_array.hpp:34,\n                 from stan/lib/stan_math/lib/boost_1.78.0/boost/numeric/odeint/algebra/multi_array_algebra.hpp:22,\n                 from stan/lib/stan_math/lib/boost_1.78.0/boost/numeric/odeint.hpp:63,\n                 from stan/lib/stan_math/stan/math/prim/functor/ode_rk45.hpp:9,\n                 from stan/lib/stan_math/stan/math/prim/functor/integrate_ode_rk45.hpp:6,\n                 from stan/lib/stan_math/stan/math/prim/functor.hpp:15,\n                 from stan/lib/stan_math/stan/math/rev/fun.hpp:198,\n                 from stan/lib/stan_math/stan/math/rev.hpp:10,\n                 from stan/lib/stan_math/stan/math.hpp:19,\n                 from stan/src/stan/model/model_header.hpp:4,\n                 from C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f1070fa5285.hpp:2:\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:180:45: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  180 |         : public boost::functional::detail::unary_function<typename unary_traits<Predicate>::argument_type,bool>\n      |                                             ^~~~~~~~~~~~~~\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nIn file included from C:/rtools43/ucrt64/include/c++/13.2.0/string:49,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/bits/locale_classes.h:40,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/bits/ios_base.h:41,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/ios:44,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/istream:40,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/sstream:40,\n                 from C:/rtools43/ucrt64/include/c++/13.2.0/complex:45,\n                 from stan/lib/stan_math/lib/eigen_3.4.0/Eigen/Core:50,\n                 from stan/lib/stan_math/lib/eigen_3.4.0/Eigen/Dense:1,\n                 from stan/lib/stan_math/stan/math/prim/fun/Eigen.hpp:22,\n                 from stan/lib/stan_math/stan/math/rev.hpp:4:\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:214:45: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  214 |         : public boost::functional::detail::binary_function<\n      |                                             ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:252:45: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  252 |         : public boost::functional::detail::unary_function<\n      |                                             ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:299:45: warning: 'template<cl\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nass _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  299 |         : public boost::functional::detail::unary_function<\n      |                                             ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:345:57: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  345 |     class mem_fun_t : public boost::functional::detail::unary_function<T*, S>\n      |                                                         ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:361:58: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  361 |     class mem_fun1_t : public boost::functional::detail::binary_function<T*, A, S>\n      |                                                          ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:377:63: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  377 |     class const_mem_fun_t : public boost::functional::detail::unary_function<const T*, S>\n      |                                                               ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:393:64: warning: \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  393 |     class const_mem_fun1_t : public boost::functional::detail::binary_function<const T*, A, S>\n      |                                                                ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:438:61: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  438 |     class mem_fun_ref_t : public boost::functional::detail::unary_function<T&, S>\n      |                                                             ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:454:62: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  454 |     class mem_fun1_ref_t : public boost::functional::detail::binary_function<T&, A, S>\n      |                                                              ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:470:67: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  470 |     class const_mem_fun_ref_t : public boost::functional::detail::unary_function<const T&, S>\n      |                                                                   ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:487:68: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  487 |     class const_mem_fun1_ref_t : public boost::functional::detail::binary_function<const T&, A, S>\n      |                                                                    ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:533:73: warning: 'template<class _Arg, class _Result> struct std::unary_function' is deprecated [-Wdeprecated-declarations]\n  533 |     class pointer_to_unary_function : public boost::functional::detail::unary_function<Arg,Result>\n      |                                                                         ^~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:117:12: note: declared here\n  117 |     struct unary_function\n      |            ^~~~~~~~~~~~~~\nstan/lib/stan_math/lib/boost_1.78.0/boost/functional.hpp:557:74: warning: 'template<class _Arg1, class _Arg2, class _Result> struct std::binary_function' is deprecated [-Wdeprecated-declarations]\n  557 |     class pointer_to_binary_function : public boost::functional::detail::binary_function<Arg1,Arg2,Result>\n      |                                                                          ^~~~~~~~~~~~~~~\nC:/rtools43/ucrt64/include/c++/13.2.0/bits/stl_function.h:131:12: note: declared here\n  131 |     struct binary_function\n      |            ^~~~~~~~~~~~~~~\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nIn file included from stan/lib/stan_math/stan/math/prim/prob/von_mises_lccdf.hpp:5,\n                 from stan/lib/stan_math/stan/math/prim/prob/von_mises_ccdf_log.hpp:4,\n                 from stan/lib/stan_math/stan/math/prim/prob.hpp:356,\n                 from stan/lib/stan_math/stan/math/prim.hpp:16,\n                 from stan/lib/stan_math/stan/math/rev.hpp:14:\nstan/lib/stan_math/stan/math/prim/prob/von_mises_cdf.hpp: In function 'stan::return_type_t<T_x, T_sigma, T_l> stan::math::von_mises_cdf(const T_x&, const T_mu&, const T_k&)':\nstan/lib/stan_math/stan/math/prim/prob/von_mises_cdf.hpp:194: note: '-Wmisleading-indentation' is disabled from this point onwards, since column-tracking was disabled due to the size of the code/headers\n  194 |       if (cdf_n < 0.0)\n      | \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nstan/lib/stan_math/stan/math/prim/prob/von_mises_cdf.hpp:194: note: adding '-flarge-source-files' will allow for more column-tracking support, at the expense of compilation time and memory\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nIn file included from stan/src/stan/model/model_header.hpp:11:\nstan/src/stan/model/model_base_crtp.hpp: At global scope:\nstan/src/stan/model/model_base_crtp.hpp:198: warning: 'void stan::model::model_base_crtp<M>::write_array(boost::random::ecuyer1988&, std::vector<double, std::allocator<double> >&, std::vector<int>&, std::vector<double, std::allocator<double> >&, bool, bool, std::ostream*) const [with M = Ex4b_model_namespace::Ex4b_model; boost::random::ecuyer1988 = boost::random::additive_combine_engine<boost::random::linear_congruential_engine<unsigned int, 40014, 0, 2147483563>, boost::random::linear_congruential_engine<unsigned int, 40692, 0, 2147483399> >; std::ostream = std::basic_ostream<char>]' was hidden [-Woverloaded-virtual=]\n  198 |   void write_array(boost::ecuyer1988& rng, std::vector<double>& theta,\n      | \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nC:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f1070fa5285.hpp:492: note:   by 'Ex4b_model_namespace::Ex4b_model::write_array'\n  492 |   write_array(RNG& base_rng, std::vector<double>& params_r, std::vector<int>&\n      | \nstan/src/stan/model/model_base_crtp.hpp:136: warning: 'void stan::model::model_base_crtp<M>::write_array(boost::random::ecuyer1988&, Eigen::VectorXd&, Eigen::VectorXd&, bool, bool, std::ostream*) const [with M = Ex4b_model_namespace::Ex4b_model; boost::random::ecuyer1988 = boost::random::additive_combine_engine<boost::random::linear_congruential_engine<unsigned int, 40014, 0, 2147483563>, boost::random::linear_congruential_engine<unsigned int, 40692, 0, 2147483399> >; Eigen::VectorXd = Eigen::Matrix<double, -1, 1>; std::ostream = std::basic_ostream<char>]' was hidden [-Woverloaded-virtual=]\n  136 |   void write_array(boost::ecuyer1988& rng, Eigen::VectorXd& theta,\n      | \nC:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f1070fa5285.hpp:492: note:   by 'Ex4b_model_namespace::Ex4b_model::write_array'\n  492 |   write_array(RNG& base_rng, std::vector<double>& params_r, std::vector<int>&\n      | \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod4b_data <- sim_data_4b |>\n\tdplyr::mutate(x_l = sim2_parms$LoD, t = as.integer(t)) |>\n\tdplyr::select(t, y, x, x_l) |>\n\tas.list()\n\nmod4b_data <- c(\n\t\"N\" = nrow(sim_data_4b),\n\t\"k\" = as.integer(max(mod4b_data$t)),\n\tmod4b_data\n)\nstr(mod4b_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 6\n $ N  : int 116\n $ k  : int 2\n $ t  : int [1:116] 1 1 2 1 1 1 2 2 2 2 ...\n $ y  : int [1:116] 1 0 0 0 0 0 0 0 0 0 ...\n $ x  : num [1:116] 1.5 3.19 1.5 3.79 4.7 ...\n $ x_l: num [1:116] 3 3 3 3 3 3 3 3 3 3 ...\n```\n:::\n\n```{.r .cell-code}\npaste0(\n\t\"Naruto checked the data and he says:\\n\",\n\tround(mean(mod4b_data$x <= mod4b_data$x_l), 4) * 100,\n\t\"% of x values are below the LoD!\\nBelieve it!\"\n) |> cat()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNaruto checked the data and he says:\n46.55% of x values are below the LoD!\nBelieve it!\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4b <- mod4b$sample(\n\tmod4b_data,\n\tseed = 5234521,\n\tparallel_chains = 4,\n\titer_warmup = 500,\n\titer_sampling = 2500,\n\tshow_messages = T\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 Exception: normal_lcdf: Scale parameter is 0, but must be positive! (in 'C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f1070fa5285.stan', line 75, column 3 to column 50)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nChain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 4 Iteration:    1 / 3000 [  0%]  (Warmup) \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 Exception: normal_lcdf: Scale parameter is 0, but must be positive! (in 'C:/Users/Zane/AppData/Local/Temp/Rtmpm0Bkna/model-5f1070fa5285.stan', line 75, column 3 to column 50)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 4 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nChain 1 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 2 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 2 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 2 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 2 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 2 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 2 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 3 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 3 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 3 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 3 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 3 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 3 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 4 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 1 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 2 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 2 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 3 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 3 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 2 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 2 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 3 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 3 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 3 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 4 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 1 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 2 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 3 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 3 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 4 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 1 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 2 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 2 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 3 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 3 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 2 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 2 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 3 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 3 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 4 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 1 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 2 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 2 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 3 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 3 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 4 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 1 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 1 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 2 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 2 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 3 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 3 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 3 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 4 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 1 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 3 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 3 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 4 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 2 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 2 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 3 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 3 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 4 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 1 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 2 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 2 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 3 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 3 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 1 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 2 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 2 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 2 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 3 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 3 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 3 finished in 1.8 seconds.\nChain 1 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 2 finished in 1.9 seconds.\nChain 4 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 1 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 1 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 4 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 1 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 4 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 1 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 4 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 1 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 4 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 1 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 4 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 1 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 4 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 1 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 4 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 1 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 4 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 1 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 4 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 1 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 4 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 1 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 4 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 1 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 4 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 1 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 4 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 1 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 4 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 1 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 4 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 1 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 4 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 1 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 4 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 1 finished in 5.2 seconds.\nChain 4 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 4 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 finished in 5.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 3.6 seconds.\nTotal execution time: 5.6 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4b$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 10\n  variable       mean   median    sd   mad       q5       q95  rhat ess_bulk\n  <chr>         <num>    <num> <num> <num>    <num>     <num> <num>    <num>\n1 lp__       -157.    -157.    1.95  1.85  -161.    -154.      1.00    4215.\n2 alpha_1[1]    2.45     2.46  0.292 0.284    1.95     2.90    1.00    8685.\n3 alpha_1[2]    3.85     3.85  0.254 0.256    3.42     4.26    1.00    9349.\n4 sigma_x       1.75     1.74  0.181 0.175    1.48     2.07    1.00    8116.\n5 beta_1[1]     0.760    0.758 0.530 0.536   -0.102    1.65    1.00    6824.\n6 beta_1[2]     1.45     1.40  1.17  1.15    -0.351    3.47    1.00    5524.\n7 beta_2[1]    -0.397   -0.392 0.197 0.197   -0.732   -0.0818  1.00    6880.\n8 beta_2[2]    -1.69    -1.61  0.666 0.640   -2.94    -0.752   1.00    5384.\n# ℹ 1 more variable: ess_tail <num>\n```\n:::\n\n```{.r .cell-code}\nstr(sim2_parms)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 7\n $ n      : num 116\n $ a1     : num [1:2] 2.5 4\n $ b1     : num [1:2] 1.7 2.2\n $ b2     : num [1:2] -0.67 -1.37\n $ sigma_x: num 1.5\n $ LoD    : num 3\n $ latent : logi TRUE\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_summary <- fit4b$summary() |>\n\tdplyr::select(variable, median, q5, q95) |>\n\tdplyr::filter(variable != \"lp__\") |>\n\tdplyr::mutate(\n\t\ttruth = c(\n\t\t\t#sim2_parms$a0,\n\t\t\tsim2_parms$a1[[1]],\n\t\t\tsim2_parms$a1[[2]],\n\t\t\tsim2_parms$sigma_x,\n\t\t\t#sim2_parms$b0,\n\t\t\tsim2_parms$b1[[1]],\n\t\t\tsim2_parms$b1[[2]],\n\t\t\tsim2_parms$b2[[1]],\n\t\t\tsim2_parms$b2[[2]]\n\t\t)\n\t)\n\npo <-\n\tggplot(fit_summary) +\n\taes(x = variable, y = median, ymin = q5, ymax = q95) +\n\tgeom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray\") +\n\tgeom_pointrange() +\n\tgeom_point(aes(y = truth), shape = 4, color = \"red\", size = 3, stroke = 1) +\n\tlabs(\n\t\tx = NULL,\n\t\ty = \"Parameter value\",\n\t\ttitle = \"Model-estimated median with 95% CI; x marks true simulation value\",\n\t\tsubtitle = \"Estimated with observed (censored) values with correction\"\n\t)\n```\n:::\n\n## Model if x was not censored\n\n::: {.cell}\n\n```{.r .cell-code}\nmod4b_data_l <- sim_data_4b |>\n\tdplyr::mutate(x_l = -9999, t = as.integer(t)) |>\n\tdplyr::select(t, y, x = x_star, x_l) |>\n\tas.list()\n\nmod4b_data_l <- c(\n\t\"N\" = nrow(sim_data_4b),\n\t\"k\" = as.integer(max(mod4b_data_l$t)),\n\tmod4b_data_l\n)\nstr(mod4b_data_l)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 6\n $ N  : int 116\n $ k  : int 2\n $ t  : int [1:116] 1 1 2 1 1 1 2 2 2 2 ...\n $ y  : int [1:116] 1 0 0 0 0 0 0 0 0 0 ...\n $ x  : num [1:116] 2.07 3.19 2.2 3.79 4.7 ...\n $ x_l: num [1:116] -9999 -9999 -9999 -9999 -9999 ...\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4b_l <- mod4b$sample(\n\tmod4b_data_l,\n\tseed = 5234521,\n\tparallel_chains = 4,\n\titer_warmup = 500,\n\titer_sampling = 2500,\n\tshow_messages = T\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 3 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 1 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 1 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 1 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 1 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 1 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 1 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 2 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 2 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 2 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 2 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 2 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 2 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 2 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 3 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 3 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 3 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 3 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 3 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 3 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 3 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 4 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 4 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 4 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 4 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 4 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 4 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 4 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 1 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 1 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 1 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 2 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 3 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 3 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 3 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 4 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 4 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 1 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 1 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 2 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 2 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 3 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 3 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 3 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 4 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 4 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 4 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 1 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 1 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 1 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 2 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 2 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 3 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 3 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 4 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 4 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 1 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 1 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 2 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 2 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 3 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 3 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 4 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 4 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 1 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 1 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 2 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 3 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 3 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 3 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 4 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 4 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 4 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 1 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 1 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 2 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 3 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 3 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 4 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 4 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 1 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 1 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 2 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 2 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 3 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 3 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 4 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 4 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 1 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 1 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 1 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 2 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 2 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 2 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 3 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 3 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 3 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 4 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 4 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 4 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 1 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 1 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 2 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 2 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 3 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 3 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 4 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 4 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 1 finished in 1.6 seconds.\nChain 2 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 3 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 3 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 4 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 2 finished in 1.7 seconds.\nChain 3 finished in 1.7 seconds.\nChain 4 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 finished in 1.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.7 seconds.\nTotal execution time: 1.9 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4b_l$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 10\n  variable       mean   median    sd   mad       q5      q95  rhat ess_bulk\n  <chr>         <num>    <num> <num> <num>    <num>    <num> <num>    <num>\n1 lp__       -166.    -165.    1.87  1.73  -169.    -163.     1.00    4661.\n2 alpha_1[1]    2.63     2.64  0.204 0.203    2.30     2.97   1.00   11142.\n3 alpha_1[2]    3.90     3.91  0.214 0.213    3.55     4.25   1.00   12564.\n4 sigma_x       1.61     1.61  0.108 0.108    1.44     1.79   1.00   10927.\n5 beta_1[1]     1.50     1.48  0.599 0.597    0.545    2.51   1.00    7405.\n6 beta_1[2]     1.21     1.19  1.09  1.09    -0.530    3.06   1.00    7679.\n7 beta_2[1]    -0.673   -0.661 0.213 0.216   -1.04    -0.342  1.00    7502.\n8 beta_2[2]    -1.26    -1.22  0.449 0.446   -2.06    -0.603  1.00    7520.\n# ℹ 1 more variable: ess_tail <num>\n```\n:::\n\n```{.r .cell-code}\nstr(sim2_parms)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 7\n $ n      : num 116\n $ a1     : num [1:2] 2.5 4\n $ b1     : num [1:2] 1.7 2.2\n $ b2     : num [1:2] -0.67 -1.37\n $ sigma_x: num 1.5\n $ LoD    : num 3\n $ latent : logi TRUE\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_summary_l <- fit4b_l$summary() |>\n\tdplyr::select(variable, median, q5, q95) |>\n\tdplyr::filter(variable != \"lp__\") |>\n\tdplyr::mutate(\n\t\ttruth = c(\n\t\t\t#sim2_parms$a0,\n\t\t\tsim2_parms$a1[[1]],\n\t\t\tsim2_parms$a1[[2]],\n\t\t\tsim2_parms$sigma_x,\n\t\t\t#sim2_parms$b0,\n\t\t\tsim2_parms$b1[[1]],\n\t\t\tsim2_parms$b1[[2]],\n\t\t\tsim2_parms$b2[[1]],\n\t\t\tsim2_parms$b2[[2]]\n\t\t)\n\t)\n\npl <-\n\tggplot(fit_summary_l) +\n\taes(x = variable, y = median, ymin = q5, ymax = q95) +\n\tgeom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray\") +\n\tgeom_pointrange() +\n\tgeom_point(aes(y = truth), shape = 4, color = \"red\", size = 3, stroke = 1) +\n\tlabs(\n\t\tx = NULL,\n\t\ty = \"Parameter value\",\n\t\ttitle = \"Model-estimated median with 95% CI; x marks true simulation value\",\n\t\tsubtitle = \"Estimated using true latent values\"\n\t)\n```\n:::\n\n## Do it the naive way\n\n::: {.cell}\n\n```{.r .cell-code}\nmod4b_data_n <- sim_data_4b |>\n\tdplyr::mutate(x_l = -9999, t = as.integer(t)) |>\n\tdplyr::select(t, y, x = x, x_l) |>\n\tas.list()\n\nmod4b_data_n <- c(\n\t\"N\" = nrow(sim_data_4b),\n\t\"k\" = as.integer(max(mod4b_data_n$t)),\n\tmod4b_data_n\n)\nstr(mod4b_data_n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 6\n $ N  : int 116\n $ k  : int 2\n $ t  : int [1:116] 1 1 2 1 1 1 2 2 2 2 ...\n $ y  : int [1:116] 1 0 0 0 0 0 0 0 0 0 ...\n $ x  : num [1:116] 1.5 3.19 1.5 3.79 4.7 ...\n $ x_l: num [1:116] -9999 -9999 -9999 -9999 -9999 ...\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4b_n <- mod4b$sample(\n\tmod4b_data_n,\n\tseed = 873215,\n\tparallel_chains = 4,\n\titer_warmup = 500,\n\titer_sampling = 2500,\n\tshow_messages = T\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 4 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 1 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 1 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 1 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 1 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 1 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 2 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 2 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 2 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 2 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 2 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 2 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 2 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 3 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 3 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 3 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 3 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 3 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 3 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 4 Iteration:  100 / 3000 [  3%]  (Warmup) \nChain 4 Iteration:  200 / 3000 [  6%]  (Warmup) \nChain 4 Iteration:  300 / 3000 [ 10%]  (Warmup) \nChain 4 Iteration:  400 / 3000 [ 13%]  (Warmup) \nChain 4 Iteration:  500 / 3000 [ 16%]  (Warmup) \nChain 4 Iteration:  501 / 3000 [ 16%]  (Sampling) \nChain 1 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 1 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 1 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 2 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 2 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 2 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 3 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 3 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 3 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 4 Iteration:  600 / 3000 [ 20%]  (Sampling) \nChain 4 Iteration:  700 / 3000 [ 23%]  (Sampling) \nChain 4 Iteration:  800 / 3000 [ 26%]  (Sampling) \nChain 1 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 1 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 1 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 2 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 2 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 3 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 3 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 3 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 4 Iteration:  900 / 3000 [ 30%]  (Sampling) \nChain 4 Iteration: 1000 / 3000 [ 33%]  (Sampling) \nChain 1 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 1 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 2 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 2 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 3 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 3 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 4 Iteration: 1100 / 3000 [ 36%]  (Sampling) \nChain 4 Iteration: 1200 / 3000 [ 40%]  (Sampling) \nChain 4 Iteration: 1300 / 3000 [ 43%]  (Sampling) \nChain 1 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 1 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 2 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 2 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 3 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 3 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 4 Iteration: 1400 / 3000 [ 46%]  (Sampling) \nChain 4 Iteration: 1500 / 3000 [ 50%]  (Sampling) \nChain 1 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 1 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 2 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 2 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 3 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 3 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 4 Iteration: 1600 / 3000 [ 53%]  (Sampling) \nChain 4 Iteration: 1700 / 3000 [ 56%]  (Sampling) \nChain 1 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 3 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 3 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration: 1800 / 3000 [ 60%]  (Sampling) \nChain 4 Iteration: 1900 / 3000 [ 63%]  (Sampling) \nChain 1 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 1 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 1 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 2 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 2 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 3 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 3 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 3 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 4 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration: 2100 / 3000 [ 70%]  (Sampling) \nChain 1 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 1 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 2 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 2 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 3 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 3 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 4 Iteration: 2200 / 3000 [ 73%]  (Sampling) \nChain 4 Iteration: 2300 / 3000 [ 76%]  (Sampling) \nChain 1 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 1 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 2 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 2 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 3 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 3 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 4 Iteration: 2400 / 3000 [ 80%]  (Sampling) \nChain 4 Iteration: 2500 / 3000 [ 83%]  (Sampling) \nChain 1 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 1 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 2 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 2 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 3 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 3 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 4 Iteration: 2600 / 3000 [ 86%]  (Sampling) \nChain 4 Iteration: 2700 / 3000 [ 90%]  (Sampling) \nChain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 2 finished in 1.7 seconds.\nChain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 3 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 Iteration: 2800 / 3000 [ 93%]  (Sampling) \nChain 4 Iteration: 2900 / 3000 [ 96%]  (Sampling) \nChain 4 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 1 finished in 1.7 seconds.\nChain 3 finished in 1.7 seconds.\nChain 4 finished in 1.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.7 seconds.\nTotal execution time: 1.9 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit4b_n$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 10\n  variable       mean   median    sd   mad        q5       q95  rhat ess_bulk\n  <chr>         <num>    <num> <num> <num>     <num>     <num> <num>    <num>\n1 lp__       -170.    -169.    1.89  1.73  -173.     -167.      1.00    4136.\n2 alpha_1[1]    2.53     2.53  0.209 0.204    2.19      2.87    1.00   10825.\n3 alpha_1[2]    3.75     3.75  0.217 0.215    3.39      4.11    1.00   10929.\n4 sigma_x       1.63     1.62  0.107 0.106    1.46      1.81    1.00   10108.\n5 beta_1[1]     0.776    0.768 0.521 0.522   -0.0606    1.64    1.00    6724.\n6 beta_1[2]     1.45     1.40  1.17  1.13    -0.390     3.46    1.00    6954.\n7 beta_2[1]    -0.404   -0.396 0.194 0.191   -0.731    -0.0970  1.00    6755.\n8 beta_2[2]    -1.69    -1.61  0.666 0.649   -2.92     -0.748   1.00    6854.\n# ℹ 1 more variable: ess_tail <num>\n```\n:::\n\n```{.r .cell-code}\nstr(sim2_parms)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 7\n $ n      : num 116\n $ a1     : num [1:2] 2.5 4\n $ b1     : num [1:2] 1.7 2.2\n $ b2     : num [1:2] -0.67 -1.37\n $ sigma_x: num 1.5\n $ LoD    : num 3\n $ latent : logi TRUE\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_summary_n <- fit4b_n$summary() |>\n\tdplyr::select(variable, median, q5, q95) |>\n\tdplyr::filter(variable != \"lp__\") |>\n\tdplyr::mutate(\n\t\ttruth = c(\n\t\t\t#sim2_parms$a0,\n\t\t\tsim2_parms$a1[[1]],\n\t\t\tsim2_parms$a1[[2]],\n\t\t\tsim2_parms$sigma_x,\n\t\t\t#sim2_parms$b0,\n\t\t\tsim2_parms$b1[[1]],\n\t\t\tsim2_parms$b1[[2]],\n\t\t\tsim2_parms$b2[[1]],\n\t\t\tsim2_parms$b2[[2]]\n\t\t)\n\t)\n\npn <-\n\tggplot(fit_summary_n) +\n\taes(x = variable, y = median, ymin = q5, ymax = q95) +\n\tgeom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray\") +\n\tgeom_pointrange() +\n\tgeom_point(aes(y = truth), shape = 4, color = \"red\", size = 3, stroke = 1) +\n\tlabs(\n\t\tx = NULL,\n\t\ty = \"Parameter value\",\n\t\ttitle = \"Model-estimated median with 95% CI; x marks true simulation value\",\n\t\tsubtitle = \"Estimated using censored values without censoring correction\"\n\t)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npo / pl / pn\n```\n\n::: {.cell-output-display}\n![](Ex4-Infection-Outcome-with-Censored-Predictor_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nall_fits <-\n\tdplyr::bind_rows(\n\t\t\"corrected\" = fit_summary,\n\t\t\"latent\" = fit_summary_l,\n\t\t\"naive\" = fit_summary_n,\n\t\t.id = \"model\"\n\t)\n\nall_fits |>\n\tggplot() +\n\taes(\n\t\tx = variable, y = median, ymin = q5, ymax = q95,\n\t\tcolor = model\n\t) +\n\tgeom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray\") +\n\tgeom_crossbar(\n\t\taes(y = truth, ymin = truth, ymax = truth),\n\t\twidth = 0.5,\n\t\tcolor = \"black\",\n\t\tfatten = 0.1\n\t) +\n\tgeom_pointrange(position = position_dodge2(width = 0.3)) +\n\tscale_color_brewer(palette = \"Dark2\") +\n\tlabs(\n\t\tx = NULL,\n\t\ty = \"Parameter value\",\n\t\ttitle = \"Model-estimated median with 95% CI; line marks true value\"\n\t)\n```\n\n::: {.cell-output-display}\n![](Ex4-Infection-Outcome-with-Censored-Predictor_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n## Model exploration\n\n**these curves are implied by the model and parameters, not by the simulated\ndata**\n::: {.cell}\n\n```{.r .cell-code}\nx_vec <- seq(-6, 12, 0.01)\nr1 <- sapply(x_vec, \\(x) inv_logit(1.5 + 0.2 - 0.67 * x))\nr2 <- sapply(x_vec, \\(x) inv_logit(1.5 + 0.7 - 1.37 * x))\n\nlayout(matrix(c(1, 2, 3, 3), ncol = 2, byrow = TRUE))\nplot(x_vec, r2 - r1, ylab = \"risk difference\", type = \"l\", xlab = \"\")\nabline(h = 0, lty = 2)\nplot(x_vec, r2 / r1, ylab = \"risk ratio\", type = \"l\", xlab = \"\")\nabline(h = 1, lty = 2)\nlab2 <- latex2exp::TeX(r\"($Pr(y_{i} = 1 \\ | \\ x_{i}, T_{i})$)\")\nplot(\n\tNULL, NULL,\n\tylim = c(0, 1),\n\txlim = c(-6, 12),\n\tyaxs = \"i\",\n\txaxs = \"i\",\n\txlab = \"Simulated log titer\",\n\tylab = lab2\n)\nlines(x_vec, r1, lty = 2, lwd = 1.5) # placebo\nlines(x_vec, r2, lty = 1, lwd = 1.5) # vaccine\n```\n\n::: {.cell-output-display}\n![](Ex4-Infection-Outcome-with-Censored-Predictor_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# IDK what's wrong with the legend, seems it doesn't like layout.\n# switch to ggplot to fix\n#legend(x = 9, y = 0.8, c('Unexposed', 'Exposed'), lty = c(2, 1), lwd = 2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nx_dens <-\n\ttibble::tibble(\n\t\tLatent = x_vec,\n\t\tObserved = dplyr::if_else(\n\t\t\tx_vec < sim2_parms$LoD,\n\t\t\tsim2_parms$LoD,\n\t\t\tx_vec\n\t\t),\n\t\tPlacebo = sim2_parms$a1[1],\n\t\tVaccine = sim2_parms$a1[2]\n\t) |>\n\ttidyr::pivot_longer(\n\t\tcols = c(Placebo, Vaccine),\n\t\tnames_to = \"t\",\n\t\tvalues_to = \"mu\"\n\t) |>\n\ttidyr::pivot_longer(\n\t\tcols = c(Latent, Observed),\n\t\tnames_to = \"o\",\n\t\tvalues_to = \"x\"\n\t) |>\n\tdplyr::mutate(\n\t\td = dplyr::if_else(\n\t\t\to == \"Latent\",\n\t\t\tdnorm(x, mean = mu, sd = sim2_parms$sigma_x),\n\t\t\tcrch::dcnorm(\n\t\t\t\tx, mean = mu, sd = sim2_parms$sigma_x,\n\t\t\t\tleft = sim2_parms$LoD, right = Inf\n\t\t\t)\n\t\t)\n\t)\n\nanno_df <-\n\tx_dens[1:4, ] |>\n\tdplyr::filter(o == \"Observed\")\n\nx_dens |>\n\tggplot() +\n\taes(x = x, y = d, linetype = t, group = t) +\n\tgeom_vline(\n\t\txintercept = sim2_parms$LoD,\n\t\tlinetype = 1, linewidth = 1, color = \"gray\"\n\t) +\n\tgeom_line(linewidth = 1.5) +\n\tgeom_point(\n\t\tdata = anno_df,\n\t\tsize = 2,\n\t\tstroke = 2,\n\t\tshape = 21,\n\t\tcolor = \"black\",\n\t\tfill = \"darkgray\"\n\t) +\n\tfacet_grid(vars(o), vars(t)) +\n\tscale_linetype_discrete(name = NULL) +\n\tscale_x_continuous(breaks = scales::breaks_pretty()) +\n\tscale_y_continuous(breaks = scales::breaks_pretty()) +\n\tlabs(\n\t\tx = \"Simulated log titer\",\n\t\ty = \"Implied probability density\"\n\t) +\n\t#coord_cartesian(expand = FALSE, ylim = c(-0.01, 0.28)) +\n\ttheme(axis.text.y = element_text(size = 10))\n```\n\n::: {.cell-output-display}\n![](Ex4-Infection-Outcome-with-Censored-Predictor_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n## Try gamma dist. for x on non-logged scale?\n\n## Do we want to work out a hierarchical model?\n\n<!-- END OF FILE -->\n",
    "supporting": [
      "Ex4-Infection-Outcome-with-Censored-Predictor_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
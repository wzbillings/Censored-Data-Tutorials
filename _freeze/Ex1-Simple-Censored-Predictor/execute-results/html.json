{
  "hash": "959b35d32dd55960a25edb8f5c1001e7",
  "result": {
    "markdown": "# Example Model 1: One censored predictor\n\n\n\n\n\n\nFor our first example model, we will consider an example where we have a single\ncensored predictor. Other than censoring, we assume the predictor is measured\nwithout error. We also assume a non-censored perfectly observed outcome,\nwhich follows a Gaussian linear model where the only predictor is that\ncensored one. (We could add additional non-censored predictors but it would\njust make this example more complicated.) The data generating process for the\noutcome, $y_i, \\ i = \\{1, 2, \\ldots, n\\}$ is\n$$\n\\begin{align*}\ny_i &\\sim \\mathrm{Normal}\\left(\\mu, \\sigma^2\\right) \\\\\n\\mu &= \\beta_0 + \\beta_1 x_i^*\n\\end{align*}\n$$\nwhere $x_i^*$ is the latent, true value of the predictor $x$. However, because\nof some imperfect measurement process, we can't observed $x_i^*$, instead we\nobserve\n$$\nx_i = \\begin{cases}\nx_{\\min}, & x_i^* \\leq x_{\\min} \\\\\nx_i^*, & x_i^* > x_{\\min}\n\\end{cases}.\n$$\nSo if we want to correctly model $y$, we will need to take the left censoring\nof $x$ into account.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlod <- 0\ngenerate_data <- function(n = 1000, xmin = 2, beta0 = 1, beta1 = 2, sigma = 5,\n\t\t\t\t\t\t\t\t\t\t\t\t\tseed = 83719273) {\n\tl <- tibble::tibble(\n\t\tx_star = rnorm(n, 5, 3),\n\t\tx = ifelse(x_star <= xmin, xmin, x_star),\n\t\tmu = beta0 + beta1 * x_star,\n\t\ty = rnorm(n, mu, sigma)\n\t)\n\t\n\to <- dplyr::select(l, x, y)\n\t\n\tout <- list(\"latent\" = l, \"observed\" = o)\n}\n\ndat <- generate_data(xmin = lod)\ndat_l <- dat$latent\ndat_o <- dat$observed\n```\n:::\n\n\nWe can take a quick look at the data to see what the relationship looks\nlike when x is censored or not.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_l |>\n\tggplot() +\n\tgeom_vline(xintercept = lod, linetype = \"dashed\", color = \"gray\") +\n\tgeom_line(\n\t\taes(x = x_star, y = 1 + 2 * x_star), color = \"red\", linetype = \"dashed\",\n\t\tlinewidth = 1\n\t) +\n\tgeom_point(aes(x = x_star, y = y), color = \"gray\", size = 2) +\n\tgeom_point(aes(x = x, y = y), color = \"black\", size = 2) +\n\tlabs(x = \"x\", y = \"y\")\n```\n\n::: {.cell-output-display}\n![](Ex1-Simple-Censored-Predictor_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nHere the gray points show the true latent values of the censored points, and\nthe black points show what we actually observed. The red line is the true\nregression line from the data generating process.\n\nFor a Bayesian model, before we can fit anything to the data we need to choose\nsuitable priors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_stan <-\n\tdat_o |>\n\tdplyr::mutate(\n\t\tcens = factor(x <= lod, levels = c(FALSE, TRUE), labels = c('obs', 'cens'))\n\t) |>\n\t# Arrange by whether or not the data is censored. Getting the right format\n\t# for Stan is kind of annoying.\n\tdplyr::arrange(cens)\n\ndat_stan <- list()\ndat_stan$y <- df_stan$y\ndat_stan$x_obs <- subset(df_stan, cens == 'obs')$x\ndat_stan$N <- length(dat_stan$y)\ndat_stan$N_obs <- length(dat_stan$x_obs)\ndat_stan$N_cens <- dat_stan$N - dat_stan$N_obs\ndat_stan$DL <- lod\n```\n:::\n\n\nLoad and compile the stan program\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cmdstanr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is cmdstanr version 0.6.1.9000\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStan path: C:/Users/Zane/Documents/.cmdstan/cmdstan-2.33.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStan version: 2.33.1\n```\n:::\n\n```{.r .cell-code}\nmod <- cmdstanr::cmdstan_model(stan_file = here::here('Ex1.stan'))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- mod$sample(dat_stan, seed = 100, parallel_chains = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.4 seconds.\nChain 4 finished in 1.5 seconds.\nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 finished in 1.6 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.5 seconds.\nTotal execution time: 1.7 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit$summary() |> print(n = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 49 × 10\n   variable        mean    median     sd    mad       q5      q95  rhat ess_bulk\n   <chr>          <num>     <num>  <num>  <num>    <num>    <num> <num>    <num>\n 1 lp__       -3677.    -3677.    5.87   5.69   -3.69e+3 -3.67e+3 1.00     1171.\n 2 x_cens[1]     -1.84     -1.64  1.27   1.30   -4.27e+0 -1.86e-1 1.00     3089.\n 3 x_cens[2]     -1.66     -1.46  1.20   1.23   -3.94e+0 -1.34e-1 1.00     2532.\n 4 x_cens[3]     -0.564    -0.415 0.516  0.411  -1.60e+0 -3.27e-2 1.00     2732.\n 5 x_cens[4]     -0.887    -0.694 0.747  0.649  -2.36e+0 -7.08e-2 1.00     3407.\n 6 x_cens[5]     -0.691    -0.524 0.607  0.516  -1.89e+0 -4.55e-2 1.00     4185.\n 7 x_cens[6]     -1.23     -0.997 0.990  0.932  -3.19e+0 -8.25e-2 1.00     3121.\n 8 x_cens[7]     -1.21     -0.956 0.976  0.900  -3.10e+0 -8.08e-2 1.00     3199.\n 9 x_cens[8]     -1.87     -1.69  1.28   1.34   -4.25e+0 -1.66e-1 1.00     2598.\n10 x_cens[9]     -0.694    -0.520 0.644  0.508  -1.98e+0 -3.65e-2 1.00     3680.\n11 x_cens[10]    -0.633    -0.461 0.592  0.470  -1.82e+0 -3.20e-2 0.999    3093.\n12 x_cens[11]    -0.842    -0.663 0.718  0.620  -2.24e+0 -5.68e-2 1.00     3502.\n13 x_cens[12]    -1.91     -1.66  1.36   1.38   -4.47e+0 -1.75e-1 1.00     2820.\n14 x_cens[13]    -0.823    -0.613 0.746  0.633  -2.32e+0 -3.66e-2 1.00     2033.\n15 x_cens[14]    -0.927    -0.695 0.811  0.677  -2.54e+0 -6.41e-2 1.00     2621.\n16 x_cens[15]    -1.84     -1.60  1.31   1.33   -4.34e+0 -1.57e-1 1.00     2399.\n17 x_cens[16]    -1.35     -1.16  1.02   1.01   -3.31e+0 -9.31e-2 1.00     2802.\n18 x_cens[17]    -0.709    -0.524 0.645  0.529  -2.00e+0 -4.00e-2 1.00     3381.\n19 x_cens[18]    -0.801    -0.602 0.718  0.603  -2.21e+0 -4.45e-2 1.00     3340.\n20 x_cens[19]    -1.99     -1.81  1.31   1.37   -4.37e+0 -2.19e-1 1.00     3165.\n21 x_cens[20]    -0.657    -0.501 0.578  0.475  -1.81e+0 -4.63e-2 1.00     3941.\n22 x_cens[21]    -1.30     -1.05  1.03   0.951  -3.32e+0 -1.02e-1 1.00     2634.\n23 x_cens[22]    -1.22     -0.978 0.970  0.912  -3.13e+0 -9.95e-2 1.00     3210.\n24 x_cens[23]    -0.828    -0.617 0.761  0.625  -2.34e+0 -4.18e-2 1.00     2306.\n25 x_cens[24]    -1.41     -1.18  1.07   1.02   -3.43e+0 -1.17e-1 1.00     3174.\n26 x_cens[25]    -0.885    -0.669 0.781  0.675  -2.41e+0 -4.71e-2 1.00     2486.\n27 x_cens[26]    -2.32     -2.18  1.45   1.49   -5.01e+0 -2.39e-1 1.00     1972.\n28 x_cens[27]    -0.967    -0.774 0.799  0.719  -2.52e+0 -6.49e-2 1.00     3713.\n29 x_cens[28]    -0.933    -0.717 0.806  0.698  -2.55e+0 -6.28e-2 1.00     3509.\n30 x_cens[29]    -1.13     -0.904 0.928  0.851  -2.91e+0 -6.70e-2 1.00     2668.\n31 x_cens[30]    -1.12     -0.896 0.916  0.858  -2.94e+0 -8.51e-2 1.00     3532.\n32 x_cens[31]    -1.47     -1.24  1.10   1.09   -3.52e+0 -1.14e-1 1.00     2676.\n33 x_cens[32]    -0.610    -0.452 0.553  0.450  -1.71e+0 -3.77e-2 1.00     4256.\n34 x_cens[33]    -0.996    -0.767 0.855  0.754  -2.72e+0 -6.10e-2 1.00     2618.\n35 x_cens[34]    -1.38     -1.15  1.07   1.02   -3.53e+0 -1.06e-1 1.00     3179.\n36 x_cens[35]    -0.985    -0.781 0.847  0.760  -2.67e+0 -5.03e-2 1.00     2845.\n37 x_cens[36]    -0.820    -0.636 0.722  0.624  -2.28e+0 -5.03e-2 1.00     3574.\n38 x_cens[37]    -1.12     -0.914 0.898  0.844  -2.94e+0 -8.18e-2 1.00     2962.\n39 x_cens[38]    -0.741    -0.573 0.642  0.550  -2.00e+0 -4.57e-2 1.00     3465.\n40 x_cens[39]    -1.72     -1.50  1.20   1.21   -3.98e+0 -1.69e-1 1.00     2488.\n41 x_cens[40]    -1.18     -0.976 0.913  0.873  -2.96e+0 -9.94e-2 1.00     2950.\n42 x_cens[41]    -1.44     -1.21  1.08   1.07   -3.54e+0 -1.23e-1 1.00     3145.\n43 x_cens[42]    -1.07     -0.850 0.885  0.799  -2.78e+0 -7.37e-2 1.00     3163.\n44 x_cens[43]    -1.29     -1.07  1.01   0.992  -3.24e+0 -8.12e-2 1.00     2119.\n45 a              0.602     0.605 0.311  0.314   9.84e-2  1.11e+0 1.00     1929.\n46 b              2.10      2.10  0.0531 0.0532  2.01e+0  2.18e+0 1.00     1921.\n47 s              4.87      4.87  0.109  0.110   4.69e+0  5.05e+0 1.00     4219.\n48 mu_x           5.06      5.06  0.0922 0.0937  4.91e+0  5.21e+0 1.00     4559.\n49 sigma_x        2.93      2.93  0.0678 0.0675  2.82e+0  3.04e+0 1.00     3875.\n# ℹ 1 more variable: ess_tail <num>\n```\n:::\n:::\n\n\n## The other method (Bjorn method)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2 <- cmdstanr::cmdstan_model(stan_file = here::here('Ex1b.stan'))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2 <- list()\ndat2$y <- df_stan$y\ndat2$x <- df_stan$x\ndat2$x_cens <- df_stan$cens\ndat2$N <- length(dat2$y)\ndat2$DL <- lod\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- mod2$sample(dat2, seed = 100, parallel_chains = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 Exception: normal_lcdf: Scale parameter is 0, but must be positive! (in 'C:/Users/Zane/AppData/Local/Temp/Rtmpq4W877/model-44107d12126b.stan', line 64, column 3 to column 55)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 1 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 9.3 seconds.\nChain 4 finished in 9.3 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 9.4 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 9.5 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 9.4 seconds.\nTotal execution time: 9.6 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2$summary() |>\n\tdplyr::filter(!startsWith(variable, \"x\")) |>\n\tprint(n = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 10\n  variable      mean     median      sd     mad       q5      q95  rhat ess_bulk\n  <chr>        <num>      <num>   <num>   <num>    <num>    <num> <num>    <num>\n1 lp__     -3099.    -3098.     23.6    23.3    -3.14e+3 -3.06e+3  1.00    1381.\n2 a            0.158     0.148   0.329   0.327  -3.79e-1  6.89e-1  1.00    2660.\n3 b            2.17      2.17    0.0564  0.0566  2.07e+0  2.26e+0  1.00    2732.\n4 s            4.90      4.90    0.109   0.110   4.73e+0  5.09e+0  1.00    6319.\n5 mu_x        -0.174    -0.0675  9.86    9.45   -1.67e+1  1.62e+1  1.00    6405.\n6 sigma_x      0.510     0.342   0.521   0.363   2.73e-2  1.57e+0  1.00    5287.\n# ℹ 1 more variable: ess_tail <num>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npost <- posterior::as_draws_array(fit2)\n```\n:::\n\n\n\n<!-- END OF FILE -->\n",
    "supporting": [
      "Ex1-Simple-Censored-Predictor_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
# One censored outcome

```{r setup}
# Setup code
library(cmdstanr)
# ggplot2 theme setup
library(ggplot2)
ggplot2::theme_set(hgp::theme_ms())
pth_base <- here::here("examples", "simple-censored-outcome")
```

Now that we've gone through a very broad overview of what censored data is,
we'll discuss a simple example with a censored outcome.

For this example, we'll stay on the theme of concentrations that we started
in the last chapter. Analyzing immunological, medical, or environmental
concentrations is a common use case of censored data that doesn't require us
to also discuss the intricacies of time-to-event analysis. This time,
we'll consider **the amount of glyphosate in household drinking water.**

## Glyphosate data simulation

In this first example, since we're trying to understand these models, we'll
**simulate our data** from a known generative model. This allows us to be
confident that our model for censored data is actually helping us to recover
the correct parameters. Once we're more comfortable with the model, we can
try to analyze some data with unknown generative processeses.

[Glyphosate](https://en.wikipedia.org/wiki/Glyphosate) is an organophosphonate pesticide originally marketed as Roundup by Monsanto. Roundup was quickly
adopted for industrial agriculture, especially after the introduction of
genetically modified Roundup-resistant crop species in the mid-90's. Due to
widespread agricultural use in the US, glyphosate is an increasingly common
groundwater contaminant, with a [Maximum Containment Level Goal of 0.7 parts
per million in tap water set by the EPA](https://web.archive.org/web/20240509003411/https://www.epa.gov/sites/default/files/2015-06/documents/epa-200.7.pdf).

1. **Source population.** Our fictional source population will be $n$ randomly
sampled households from a fictional city, indexed from $i = 1, \ldots, n$. We
only have one measurement per household. For the purposes of our study,
we'll assume that each of these houses has their own water supply (which is
unrealistic but sufficient for a censored data tutorial).
1. **Outcome variable.** For this example, our outcome (or dependent) variable
is $y_i$, the log concentration of glyphosate in parts per million (ppm) detected
from the tap in household $i$ using an analytical test.
1. **Censoring structure.** Our investigators have decided to use [the test described in this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6163928/), which has a lower limit of detection of 2 ÂµM. Given a molar mass of 169.07 g/Mol
for glyphosate, we can convert this to an LoD of 0.33 ppm, just under half of
the MCLG. We assume there is no upper LoD or interval censoring.
1. **Independent variables.** For the sake of this example, we will measure a
few independent variables at the household level. Without doing any research
on the actual patterns of glyphosate distribution in groundwater, we'll assume
that glyphosate concentration is affected by:
	1. distance to the nearest agriculture site (km).
	1. whether the home uses glyphosate-based pesticides for personal gardening.
	1. whether the home has a water filter on the primary tap.

To get our data, we'll first randomly generate our covariates. Let's assume that
our town of interest is a square, so we can normalize all of the distances so
that each side of the square has length 1. Then (again somewhat unrealistically)
we'll assume that home X and Y coordinates are independently drawn from a
uniform distribution on $(0, 1)$. For convenience, we'll place the only farm
in town at $(0.5, 0.5)$ and calculate the distances. Then since the other
two independent variables are binary, we'll randomly sample those for each house,
say with respective probabilities $0.2$ and $0.4$.

```{r gly data independent variables}
set.seed(370)
N <- 147
gly_preds <-
	tibble::tibble(
		house_x_coord = runif(N, 0, 1),
		house_y_coord = runif(N, 0, 1),
		dist_from_farm = sqrt((house_x_coord - 0.5)^2 + (house_y_coord - 0.5)^2),
		personal_gly_use = rbinom(N, 1, 0.2),
		water_filter_use = rbinom(N, 1, 0.4)
	)
head(gly_preds)
```

Now we need to describe our data generating model for the outcome. Of course,
I am just going to randomly pick some parameters and mess around until they
look about right -- we know that our glyphosate levels should be somewhere in
the neighborhood of $(0, 1.4)$-ish. We'll use a linear model, which means
we assume that:
$$
\begin{aligned}
\log(y_i^*) &\sim \text{Normal}(\mu_i, \sigma^2) \\
\mu_i &= \beta_0 + \beta_1 x_{1, i} + \beta_2 x_{2, i} + \beta_3x_{3, i}.
\end{aligned}
$$
Here, $y_i$ is the concentration of glyphosate in tap water of house $i$,
$$x_{1, i}$$ is the distance from house $i$ to the farm, $x_{2, i}$ is the
personal glyphosate use variable, and $x_{3, i}$ is the water filter use
variable. So we need to pick all four of those $\beta_p$ coefficients and the
value of $\sigma^2$, the residual variance, before we can simulate our glyphosate
levels.

```{r simulating y values}
gly_data <-
	gly_preds |>
	dplyr::mutate(
		mu = 0.8 - 4 * dist_from_farm + 0.5 * personal_gly_use -
			0.4 * water_filter_use,
		y_star = exp(rnorm(N, mu, 0.25))
	)

summary(gly_data)
```

You can see from the above simulation code that the values I ended up choosing
are as follows:

$$
\begin{aligned}
\log(y_i^*) &\sim \text{Normal}(\mu_i, 0.5^2) \\
\mu_i &= -2.5 + 2\cdot x_{1, i} + 0.5\cdot x_{2, i} -0.4\cdot x_{3, i}.
\end{aligned}
$$
These values seemed to give a reasonable range of $y$ values (on the natural
scale), and have signs that made sense to me. The intercept represents
the concentration of glyphosate expected in tap water for a person who lives
on the farm, no personal glyphosate use, and no water filter, and is
about $2.23$ ppm, which is quite high and perhaps expected for the point source
of the contaminant. With these parameters, we will have
$`r round(mean(gly_data[['y_star']] <= 0.33) * 100, 1)`\%$ of data points below
the limit of detection, which is not ideal (of course the ideal is zero
percent), but not too bad either.

Our censoring model looks like this:

$$
y_i = \begin{cases}
L, & y_i^* < 0.33 \text{ ppm} \\
y_i^*, & \text{otherwise}
\end{cases}.
$$
Our censoring indicator $C_i$ will look like this:

$$
c_i = \begin{cases}
1, & y_i^* < 0.33 \text{ ppm} \\
0, & \text{otherwise}
\end{cases}.
$$
Let's first apply the censoring to our data. We'll arbitrarily choose $L = 0$.
Then we'll take a look at the data we would actually observe.

```{r}
# Dataset including latent variables
# Do the censoring
L <- 0.1
gly_data_lnt <-
	gly_data |>
	dplyr::mutate(
		# Create the censoring indicator
		c = ifelse(y_star <= 0.33, 1, 0),
		# Create the censored outcome
		y = ifelse(c == 1, L, y_star)
	)

# Dataset including ONLY the observed variables
gly_data_obs <- gly_data_lnt |>
	dplyr::select(dist_from_farm, personal_gly_use, water_filter_use, c, y)

head(gly_data_obs)
```

Note that setting $y_i = 0.1$ if the value is censored is **completely arbitrary**.
Many people will set it to a value like the LoD, or half the LoD, or some
crazy thing with $\sqrt{2}$ in it, and then pretend those are the real values.
**All of these arbitrary values are equally bad.** Let's look at the
distribution of the latent and observed values just to show this.
In real life, we can't see this, but this example should remind us that picking
an arbitrary number is not very good.

```{r}
# Arrange the data correctly for plotting
gly_data_lnt |>
	dplyr::select(
		"observed" = y,
		"latent" = y_star
	) |>
	tidyr::pivot_longer(dplyr::everything()) |>
	# Now make the plot
	ggplot() +
	aes(x = value) +
	geom_histogram(
		boundary = 0,
		binwidth = 0.1,
		color = "black",
		fill = "gray"
	) +
	facet_wrap(vars(name)) +
	ggtitle(paste0("Censored values coded as ", L))
```

Let's also take a look at what the data would have looked like if we set, say
$L = 0.33$ (the LoD).

```{r}
gly_data_lnt |>
	# Set censored values to LoD
	dplyr::mutate(y = ifelse(y == L, 0.33, y)) |>
	# Arrange the data for the plot
	dplyr::select(
		"observed" = y,
		"latent" = y_star
	) |>
	tidyr::pivot_longer(dplyr::everything()) |>
	# Make the plot
	ggplot() +
	aes(x = value) +
	geom_histogram(
		boundary = 0,
		binwidth = 0.1,
		color = "black",
		fill = "gray"
	) +
	facet_wrap(vars(name)) +
	ggtitle("Censored values coded as LoD")
```

We can see how this histogram makes the censored values look like actual data
(cat screaming emoji)!! Whereas the previous set of histograms with a spike at
zero should signal that there is something strange going on in the data. So
substitution can cause data to be misleading. For this reason, it can sometimes
be useful for analysts to record values as "Nondetect" or "< LoD" in the dataset
(or some other kind of text indicating it is not a regular number),
forcing the analyst to clean up the data before it can be statistically examined.
The problem can be somewhat avoided if we include an explicit indicator of
censoring in our data, like so.

```{r}
gly_data_lnt |>
		# Set censored values to LoD
	dplyr::mutate(y = ifelse(y == L, 0.33, y)) |>
	dplyr::select(
		"observed" = y,
		"latent" = y_star,
		c
	) |>
	tidyr::pivot_longer(-c) |>
	# Now make the plot
	ggplot() +
	aes(x = value, fill = factor(c)) +
	geom_histogram(
		boundary = 0,
		binwidth = 0.1,
		color = "black",
		alpha = 0.5,
		position = "stack"
	) +
	facet_wrap(vars(name)) +
	scale_fill_manual(values = c("#E69F00", "#56B4E9"), name  = "Below LoD?") +
	ggtitle(paste0("Censored values coded as LoD"))
```

```{r}
gly_data_lnt |>
	dplyr::select(
		"observed" = y,
		"latent" = y_star,
		c
	) |>
	tidyr::pivot_longer(-c) |>
	# Now make the plot
	ggplot() +
	aes(x = value, fill = factor(c)) +
	geom_histogram(
		boundary = 0,
		binwidth = 0.1,
		color = "black",
		alpha = 0.5,
		position = "stack"
	) +
	facet_wrap(vars(name)) +
	scale_fill_manual(values = c("#E69F00", "#56B4E9"), name  = "Below LoD?") +
	ggtitle(paste0("Censored values coded as ", L))
```

Here, we can see that the histogram conflates part of the censored and
non-censored values because of the binwidth we set. All that is to show, when
there is a possibly of censored data, we should be extra careful as analysts to
make sure we aren't computing incorrect statistics.

As another instructive example, let us first attempt to estimate the mean and SD
of the glyphosate concentrations. We know an unbiased estimate of marginal mean
and CI (that is, the statistic if we ignore all of the `x` values), because we
have the underlying latent values. So let's estimate those first.
(Because we have a normal distribution, we could probably get the analytical
marginal mean assuming unknown $x_i, p$ values, but we won't do that here.)
In R, we can quickly construct the Wald-type CI based on the `t`-distribution
using the `t.test()` function.

```{r}
latent_t_test <-
	gly_data_lnt$y_star |>
	# Remember we made a log-normal assumption so we take the log here
	log() |>
	t.test() |>
	broom::tidy() |>
	# Re-exponentiate the results
	dplyr::mutate(dplyr::across(c(estimate, conf.low, conf.high), exp))
print(latent_t_test)
```

Now, if we compute the same test using the observed values, we can see what
happens.

```{r}
observed_t_test <-
	gly_data_obs$y |>
	# Remember we made a log-normal assumption so we take the log here
	log() |>
	t.test() |>
	broom::tidy() |>
	# Re-exponentiate the results
	dplyr::mutate(dplyr::across(c(estimate, conf.low, conf.high), exp))
print(observed_t_test)
```

The estimate is much lower! In fact, the 95% CI doesn't even cover the latent
estimate! Of course, **we can arbitrarily change the estimate by recoding the
censored values.** If we bumped them up to the LoD, the estimate would go up
and if we made them lower, it would go down.

So, then, what are we to do?

## Integration method for censored data

### Frequentist models

### Bayesian models

<!--

## Lower limit of detection

For the first example, we'll work with an outcome that has a lower limit of
detection. First we need to simulate the data, which means we need to write
out a generative model for the data. We'll randomly sample `x` for the purposes
of generating data, but for the purposes of our model we'll assume `x_i` is
a completely observed covariate and thus is known and does not need a random
component in the model.

$$
\begin{align*}
y_i &= \begin{cases}
\mathrm{DL}, & y^*_i \leq \mathrm{DL} \\
y^*_i, & y^*_i > \mathrm{DL}
\end{cases} \\
y^*_i &\sim \mathrm{Normal}\left(\mu_i, \sigma^2\right) \\
\mu_i &= \alpha + \beta \cdot x_i \\
i &= 1, 2, \ldots, n
\end{align*}
$$
Here, DL is the [D]{.underline}etection [L]{.underline}imit, aka the lower limit
of detection for the variable. Of course in our generative model, we have
set $\alpha$, $\beta$, and $\sigma^2$ to be fixed population parameters, but
for Bayesian inference we would need to assign suitable priors. Let's set the
values and simulate our data. The parameters I set for this example are as follows.

```{r, echo = FALSE}
set.seed(578189)
sim_parms <- list(
	N = 271,
	alpha = 72,
	beta = 3,
	sigma = 5,
	DL = 80
)

sim_llod <- function(N, alpha, beta, sigma, DL) {
	return(
		tibble::tibble(
			x = runif(N, 0, 10),
			y_star = rnorm(N, alpha + beta * x, sigma),
			cens = (y_star <= DL),
			y = dplyr::if_else(cens, DL, y_star)
		)
	)
}

sim_data <- do.call(sim_llod, sim_parms)
perc <- sim_data$cens |> mean() |> round(digits = 4) |> (\(x) (x * 100))()
```

| Parameter     | Value | Meaning                       |
|---------------|-------|-------------------------------|
| $n$           | 271   | Sample size                   |
| $\alpha$      | 72    | Regression intercept          |
| $\beta$       | 3     | Regression slope              |
| $\sigma$      | 5     | Standard deviation of outcome |
| $\mathrm{DL}$ | 80    | Lower limit of detection      |

The $x$-values were drawn from a uniform distribution on $(0, 10)$. Since we
know the true population parameters for our simulation, we can plot the data to
see the effect of the censoring process on our observed $y$ values.

```{r, echo = FALSE}
sim_data |>
	ggplot() +
	aes(x = x, y = y_star) +
	geom_hline(
		yintercept = sim_parms$DL,
		alpha = 0.5,
		linewidth = 1,
		linetype = "dashed",
		color = "darkgray"
	) +
	geom_point(
		data = subset(sim_data, cens),
		aes(x = x, y = y_star),
		color = "darkgray"
	) +
	geom_segment(
		data = subset(sim_data, cens),
		aes(x = x, xend = x, y = y_star, yend = y),
		color = "gray",
		alpha = 0.25,
		lwd = 1
	) +
	geom_point(
		data = subset(sim_data, !cens),
		aes(x = x, y = y),
		color = "black"
	) +
	geom_point(
		data = subset(sim_data, cens),
		aes(x = x, y = y),
		#shape = 21,
		color = "black",
		#fill = "gray"
	) +
	annotate(
		geom = "text",
		x = 9,
		y = sim_parms$DL - 1.75,
		size = 6,
		label = paste0("LoD: ", sim_parms$DL)
	) +
	coord_cartesian(
		expand = FALSE,
		xlim = c(-0.1, 10.1),
		ylim = c(60, 110)
	) +
	labs(
		x = "Independent variable",
		y = "Dependent variable"
	)
```

In this plot, the black data points show our observed data. For those
observations where the $y$ value was below the limit of detection and thus
censored, the gray points show the true latent values, which we could have
observed with a perfect measurement process. The gray line segments connect each
latent measurement to its corresponding observed measurement.

Approximatly $`r perc`\%$ of data points were below the limit of detection and
were therefore censored. Of course in real life, we would only observe the
black points (observed values), and the gray points would be unobservable to
us. But for the purposes of understanding how to analyze censored data,
visualizing how different the observed and latent datasets are is quite
valuable and informative. Since the datasets look so different, we should not
be surprised that our regression estimates would be incorrect if we treated all
of the censored values as the same constant value, or ignored them entirely!

So, if our standard linear regression model that we know and love (even the
Bayesian version) would give us incorrect estimates using any of these
naive methods, how then are we to proceed? According to the Stan manual
[@StanManual, chap. 4], there are two main ways of handling the censoring in
the outcome in our model. The first of these methods relies on imputation and
the second on integration of the likelihood function and manual updating of the
target likelihood in Stan. The imputation method is conceptually easier and
less mathematically daunting, so we begin our treatment there.

### Imputation-type method

The first method for dealing with censored data treats the censored values as
missing values where the latent value is constrained to fall within a specific
range. For a normally distributed outcome, all values below the lower limit
of detection are constrained to fall within $(-\infty, \mathrm{DL})$.

READ THAT PART OF RETHINKING AND EXPLAIN HOW MISSING DATA WORKS HERE!!!

To implement such a model in Stan, we need to pass in the number of observed
and the number of censored values and the observed y-values in Stan. We then
declare the censored $y$-values as a parameter in the Stan code, meaning they
will be sampled from their constrained distribution during the fitting process,
whereas the observed $y$ values will be used to update the parameter estimates.

First, let's look at the Stan code for this model.

SHOW THE STAN CODE HERE.

Since the data need to be in kind of a clunky format to use this method, we
first need to do some wrangle and get the data in the correct format for Stan.

```{r}
dat_2a <- list()
with(
	sim_data, {
		dat_cens <- subset(sim_data, cens)
		dat_obs <- subset(sim_data, !cens)
		dat_2a$N_cens <<- nrow(dat_cens)
		dat_2a$N_obs <<- nrow(dat_obs)
		dat_2a$y_obs <<- dat_obs$y
		dat_2a$x_obs <<- dat_obs$x
		dat_2a$y_cens <<- dat_cens$y
		dat_2a$x_cens <<- dat_cens$x
		dat_2a$DL <<- as.integer(sim_parms$DL)
	}
)

str(dat_2a)
```

Now we can compile the Stan program (via `cmdstanr` as usual).

```{r}
mod_pth <- here::here(pth_base, "Ex2a.stan")
mod_2a <- cmdstanr::cmdstan_model(mod_pth, compile = FALSE)
mod_2a$compile(pedantic = TRUE, force_recompile = TRUE)
```

And since the program compiles correctly, we can use Stan's sampling algorithm
to generate samples from the posterior distribution. We'll run 4 chains in
parallel with 500 warmup iterations and 5000 sampling iterations per chains,
with all of the other control parameters (e.g. maximum treedepth and adaptive
delta) left at the `cmdstan` defaults. This many samples is overkill for this
problem, but it is also quite fast and thus we can do many samples just to be
safe.

```{r}
fit_2a <- mod_2a$sample(
	dat_2a, seed = 100, parallel_chains = 4,
	iter_warmup = 500,
	iter_sampling = 5000
)

# Extract the posterior samples in a nicer format for later
post_2a <- posterior::as_draws_df(fit_2a)
```

The first thing we should do after sampling is check for any diagnostic
warnings. We have access to all of the individual diagnostics, but fortunately
`cmdstan` has a built-in diagnostic checker to flag any potential problems.

```{r}
fit_2a$cmdstan_diagnose()
```

Great, no issues with the sampling procedure, that is what we like to see.
Let's manually check the trace plots for our main three parameters of interest.
(We could also check the plots for all of the imputed y-values, but these
are unlikely to be interesting or useful, any problems should hopefully
propagate through to the interesting parameters.)

```{r}
bayesplot::mcmc_combo(post_2a, pars = c('alpha', 'beta', 'sigma'))
```

Those look like nice healthy trace plots, so with that combined with our
diagnostic check, it seems that the chains mixed well and explored the
posterior distribution. We can also check if those parameters were correlated.

```{r}
bayesplot::mcmc_pairs(post_2a, pars = c('alpha', 'beta', 'sigma'))
```

We see that the slope and intercept estimates were strongly correlated, which
makes sense, and the sigma parameter was slightly correlated with both of
those but not strongly with either. We can notice here that the histograms for
$\beta$ and $\sigma$ are not quite centered at the true values, but they
do have some probability mass at those true values. Let's look at the median
estimates and CIs from our samples.

```{r}
par_sum <-
	fit_2a$summary(variables = c("alpha", "beta", "sigma"))
par_sum |> knitr::kable()
```

We can also plot those along with the true values for reference.

```{r}
#| code-fold: true
#| code-summary: "Show plot code (messy)"
truth <- tibble::tibble(
	name = c("alpha", "beta", "sigma"),
	value = c(sim_parms$alpha, sim_parms$beta, sim_parms$sigma)
)

hd <- post_2a |>
	tibble::as_tibble() |>
	dplyr::select(alpha, beta, sigma) |>
	tidyr::pivot_longer(cols = dplyr::everything())

ggplot() +
	aes(x = value) +
	geom_histogram(
		data = subset(hd, name == "alpha"),
		boundary = 0,
		binwidth = 0.25,
		col = "black",
		fill = "gray"
	) +
	geom_histogram(
		data = subset(hd, name == "beta"),
		boundary = 0,
		binwidth = 0.05,
		col = "black",
		fill = "gray"
	) +
	geom_histogram(
		data = subset(hd, name == "sigma"),
		boundary = 0,
		binwidth = 0.1,
		col = "black",
		fill = "gray"
	) +
	geom_vline(
		data = truth,
		aes(xintercept = value),
		linetype = "dashed",
		linewidth = 1,
		color = "red"
	) +
	facet_wrap(~name, scales = "free") +
	labs(x = NULL)
```

From these histograms, we can see that while there is a decent amount of
samples close to the true values of alpha and beta, the posterior distributions
are not centered around the true values. At the time of writing, I am not sure
if that is a fixable problem or just something we have to deal with from having
imperfectly observed data.

We can also do a check of how close the imputed $y$ values were on average to
the actual $y$ values.

```{r}
y_cens_sum <-
	fit_2a$summary(variables = paste0('y_cens[', 1:dat_2a$N_cens, ']'))

dat_comp <-
	sim_data |>
	subset(cens) |>
	dplyr::select(y_star) |>
	dplyr::bind_cols(y_cens_sum) |>
	dplyr::mutate(
		col = dplyr::case_when(
			(mean >= y_star) & (q5 <= y_star) ~ TRUE,
			(mean <= y_star) & (q95 >= y_star) ~ TRUE,
			TRUE ~ FALSE
		)
	)

# ggplot(dat_comp) +
# 	aes(x = y_star, y = mean, ymin = q5, ymax = q95, color = col) +
# 		geom_abline(
# 			slope = 1, intercept = 0, linetype = 2, linewidth = 1,
# 								alpha = 0.5
# 			) +
# 	geom_errorbar(alpha = 0.25) +
# 	geom_point() +
# 	coord_fixed() +
# 	scale_color_manual(
# 		values = c("orange", "turquoise"),
# 		name = "CI crosses diagonal"
# 	)

ggplot(dat_comp) +
	aes(x = (y_star - mean)) +
	geom_histogram(boundary = 0, binwidth = 1, color = "black", fill = "gray") +
	scale_x_continuous(breaks = seq(-10, 10, 2), limits = c(-10, 10)) +
	labs(
		x = "True value - mean estimated value"
	)
```

TODO make this relative error instead to make it easier to understand.

### Integration-type method

The second method relies on calculating the direct contribution of the
censored data measurements to the likelihood by integrating the density over
the region where censored data can occur. That is, if the $i$th observation is
below the detection limit, we know that the contribution of that observation
to the sample likelihood is
$$
\mathcal{L}(\theta \mid y_i) = P(Y_i \leq \mathrm{DL}) = \int_{-\infty}^{\mathrm{DL}}f(y_i \mid \theta) \ dy = \lim_{a \to -\infty} \left[F(y_i \mid \theta)\right]_{a}^{\mathrm{DL}},
$$
which is why we refer to this method as "integrating out" the censored values.

By adapting the Stan code from the manual [@StanManual, cp. 4] to include
$x$ values in the calculation of the mean, we can implement this method for
dealing with our censored $y$ values. First we'll load and compile the Stan model.

```{r model 2b compilation, message=FALSE, warning=FALSE}
mod_pth <- here::here(pth_base, "Ex2b.stan")
mod_2b <- cmdstanr::cmdstan_model(mod_pth, compile = FALSE)
mod_2b$compile(force_recompile = TRUE)
```

<!-- debug this / figure out if possible after book is working again
```{.stan include=mod_pth}
```


As you can see from the above program, the data needs to be in a different
format for this method. Actually, it's much easier to set up the data in the
way this program specifies, and it's very similar to the data frame we already
have. We just need a list and a few other components.

```{r model 2b data}
dat_2b <- list()
dat_2b$N <- nrow(sim_data)
dat_2b$N_cens <- sum(sim_data$cens)
dat_2b$y <- sim_data$y
dat_2b$cens <- as.integer(sim_data$cens)
dat_2b$x <- sim_data$x
dat_2b$DL <- as.integer(sim_parms$DL)

str(dat_2b)
```

Now that we have the program ready and the data set up, we can give the data
to the program and do some MCMC sampling. We'll use a similar setup
that we did for the previous example, namely 4 parallel chains which each run
500 warmup iterations and 1000 sampling iterations (no need for overkill like
we did before).

```{r model 2b sampling}
fit_2b <- mod_2b$sample(
	dat_2b, seed = 100, parallel_chains = 4,
	iter_warmup = 500,
	iter_sampling = 1000,
	show_messages = FALSE
)

# Extract the posterior samples in a nicer format for later
post_2b <- posterior::as_draws_df(fit_2b)
```

We didn't get any warnings or errors, which means that the model finished the
sampling procedure without any major errors, and we should next check the
diagnostics.

```{r model 2b diagnose}
fit_2b$cmdstan_diagnose()
```

Everything looks good here, but let's again look at the traceplots.

```{r model 2b traceplot}
bayesplot::mcmc_combo(post_2b, pars = c('alpha', 'beta', 'sigma'))
```

We got some nice, healthy looking fuzzy caterpillars, so now we can be
confident in our summary results. So now let's finally look at the parameter
estimates.

```{r}
fit_2b$summary(variables = c('alpha', 'beta', 'sigma'))
```

These estimates are pretty similar to the estimates from the other method,
which is good in a way because it means both methods are similar. The frequentist tobit model estimate is also similar (see the appendix).

Unfortunately, none of the three models to estimate the
regression value while taking the censoring into account produce estimates that
are exactly the same as the true simulation parameters. However, unlike the
much worse naive model estimates, at least our uncertainty intervals correctly
contain the true values this time. So we cannot fully erase the effect of the
flawed observation process on our data, but we can do a lot better by
taking the censored data into consideration.

-->

## Appendix: imputation methods {.appendix .unnumbered}

## Appendix: tobit model check {.appendix .unnumbered}

Since we're dealing with one censored outcome with a known limit of detection,
there are actually some well-developed frequentist methods for this problem.
Namely, we can use a **tobit model**, which specificies the likelihood
model in the same way we did for the bayesian estimation method, and works
very similarly to the second method where we integrate out the censored data points. However,
instead of specifying priors to get a posterior distribution via Bayes' theorem, we instead estimate the parameters by finding the parameters which maximize the sample likelihood.

Many models for censored outcomes with a variety of distributions are implemented in the R core package `survival`, but the formula for specifying a tobit model with a gaussian outcome distribution correctly is very unintuitive. Thankfully, the package `AER` provides a simple `tobit()` wrapper which translates a more standard formula into the appropriate form for the `survReg()` function and fits the model. Fitting our model using `AER::tobit()` is simple.

```{r tobit with AER}
tobit_model <- AER::tobit(
	y ~ x,
	data = sim_data,
	left = sim_parms$DL,
	right = Inf,
	dist = "gaussian"
)

summary(tobit_model)
```

If we want a lot of compatibility with standard R functions however (e.g.
`broom::tidy()` to get the confidence intervals for the parameters), we need
to use `survreg`. Fortunately the documentation for `AER::tobit()` explains
how the formula is transmogrified.

```{r tobit with survreg}
U <- sim_parms$DL
survreg_model <- survival::survreg(
	survival::Surv(y, y > U, type = 'left') ~ x,
	data = sim_data,
	dist = "gaussian"
)
summary(survreg_model)
```

We can see that the two models are exactly the same. But since we've used
a model from `survival`, we get the benefit of widespread compatibility with
other `R`-ecosystem functionality. For example, we can easily get confidence
intervals for all three estimated parameters with `broom`.

```{r tobit confidence intervals}
broom::tidy(survreg_model, conf.int = TRUE)
```

Or at least I thought we could. Apparently there is not a built-in method to
give the CI for the scale parameter, and we have to do it ourselves.

```{r tobit scale CI}
#| code-fold: true
#| code-summary: "Code for 95% CI for scale"
paste0(
	"Scale estimate: ",
	round(exp(1.58), 2),
	", 95% CI: ",
	round(exp(1.58 - 1.96 * 0.0496), 2),
	" - ",
	round(exp(1.58 + 1.96 * 0.0496), 2),
	"."
)
```

Anyways, we can compare these to the Bayesian estimates above and see that they
are quite similar.

<!-- END OF FILE -->

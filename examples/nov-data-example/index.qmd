# Example Model 4: Logistic regression with censored predictors

::: {.callout-important}
The contents of this page might change at any time -- this example is 
**under construction**!
:::

```{r setup}
base_pth <- here::here("examples", "nov-data-example")
knitr::read_chunk(here::here(base_pth, "setup.R"))
knitr::read_chunk(here::here(base_pth, "one-group-model.R"))
knitr::read_chunk(here::here(base_pth, "two-group-model.R"))
```

```{r}
#| label: Package Loading
#| message: false
```

For the next example model we have enough background knowledge to implement
a model for a problem that my group has been trying to tackle recently, and
that is somewhat common with the type of data that I work with. Suppose we want
to test the efficacy of a novel vaccine candidate in a clinical trial.

Typically, these vaccines have **immunological correlates of protection**,
some value we can measure that gives a general idea of how strong a person's
immune response was, and correlates with their probability of getting a disease.
One of the most common types of these measurements are antibody titers, where
typically a high antibody titer is protective and corresponds to a lower
probability of disease. If we have a clinical trial where we record if
patients get the disease (after challenge or after a sufficiently long
followup period, for this example the details are not too important as long
as we assume the infection status is measured accurately), we can model how
these measurements are related to protection via **logistic regression**.

## Model with one patient group

For the first model, we'll consider a simpler case where we only have one
group of patients. This model would be appropriate for, e.g., an observational
study where all patients are given the vaccine of interest.

The data generating model is as follows:

$$
\begin{align*}
y_i &\sim \text{Bernoulli}\left(p\right) \\
\mathrm{logit}(p) &= \alpha + \beta \cdot x_i
\end{align*}
$$
where $y_i$ is a binary outcome where 1 indicates infection and 0 indicates
no infection, and $x_i$ is our antibody titer. However, the specific problem
we deal with in practice is that these antibody titers tend to have lower
limits of detection. Thus, we need to add an observation model to our
data generating process to reflect the incomplete observations we obtain of $x$.

$$
\begin{align*}
y_i &\sim \text{Bernoulli}\left(p_i\right) \\
\mathrm{logit}(p_i) &= \alpha + \beta \cdot x^*_i \\
x_i^* &\sim \mathrm{Normal}\left(\mu_x, \sigma^2_x\right) \\
x_i &= \begin{cases}
U, & x^*_i < \mathrm{LoD} \\
x^*_i, & x^*_i \geq \mathrm{LoD}
\end{cases} \\
\end{align*}
$$
where $U \in \mathbb{R}$ is some value that we write down whenever $x_i$ is
censored.
Here, we assume that we work with the $x$ variable on the log scale at all times,
mostly cause it's annoying and confusing to write out all the logs every time,
so we could also write
$$x_i^* = \mathrm{log} \left(z^*_i\right)$$
and say $z^*_i$ is the actual latent un-logged titer. We also assume that we can
write down
$$
c_i = I(x_i^* \geq \mathrm{LoD}) = I(x_i = U),
$$
as an indicator variable whether the $i$th observation of $X$ is censored. If
we cannot write down $C$ (due, perhaps, to improper coding of the data), then
we cannot correct for censoring in the same way.

Now that we have the data generating process written out, we can simulate
some example data. Note that in this example, we can interpret $\alpha$ as the
log-odds of infection if a person were to have no antibodies. For example,
if we assume that this probability is $50\%$ we would apply the logit
transformation to get that $\alpha = 0$. However, let's assume that the
inoculum dose is quite high and during our subject selection process we've
included anyone who might have a genetic resistance to the disease (i.e.,
FUT2- individuals for norovirus). So let's say if a person has zero antibodies,
their probably of getting sick should be $90\%$. Then,
$\log(0.9 / 0.1) \approx 2.2$.

We then want our true $\beta$ value to be negative, indicating that
as the number of antibodies rise, the log-odds of infection decrease. We can
interpret $\beta$ as the change in the log-odds ratio associated with a
one-unit change in antibody titer -- the nonlinearity here makes it a bit
more difficult to interpret this effect. We can, however, interpret $\exp(\beta)$ as the odds ratio between individuals with titer $x_i + 1$ and 
individuals with titer $x_i$. This corresponds to a nonlinear change in risk
that depends on the value of $x_i$. However, if we want the odds of infection
to halve for each 1 unit increase in antibody titer, we would set
$\beta = -\log(2) \approx -0.7$.

Finally, we need to choose the LoD, $U$, $\mu_x$ and $\sigma_x$. These can pretty
much be whatever we want, so long as $\sigma_x$ is positive, but we want to
choose values that give us a sensible simulation. I selected $\mathrm{LoD} = 0$,
$U = -1$, $\mu_x = 2$, and $\sigma_x = 2$ after playing around with the
simulation for a bit.

```{r}
sim_parms <- list(
	n = 110,
	alpha = 2.2,
	beta = -1.37,
	mu_x = 2,
	sigma_x = 2,
	LoD = 0,
	U = -1,
	seed = S
)

inv_logit <- function(x) {return(1 / (1 + exp(-x)))}

sim_one_group <- function(n, alpha, beta, mu_x, sigma_x, LoD, U,
													latent = TRUE, seed = NULL) {
	if (!is.null(seed)) {
		set.seed(seed)
	}
	
	out <- tibble::tibble(
		x_star = rnorm(n, mu_x, sigma_x),
		x = ifelse(x_star < LoD, U, x_star),
		p = inv_logit(alpha + beta * x_star),
		y = rbinom(n, size = 1, prob = p)
	)
	
	if (isFALSE(latent)) {
		out <- dplyr::select(out, x, y)
	}
	
	return(out)
}

sim_data <- do.call(sim_one_group, sim_parms)
```

Now that we've generated some data, let's take a quick look.

Of course visualizing the relationship between a binary outcome and a
continuous predictor is in some sense more complex than visualizing the
relationship between a continuous outcome and a continuous predictor.

First, let's look at how the distribution of the predictor variable changes
if we condition on the outcome.

```{r}
sim_data |>
	tidyr::pivot_longer(cols = c(x, x_star)) |>
	dplyr::mutate(
		yf = factor(
			y,
			levels = c(0, 1),
			labels = c("Not infected", "Infected")
		),
		name = factor(
			name,
			levels = c("x_star", "x"),
			labels = c("Latent variable", "Observed variable")
		)
	) |>
	ggplot() +
	aes(x = value, fill = yf) +
	geom_vline(
		xintercept = 0,
		linetype = "dashed",
		color = "black",
		linewidth = 1
	) +
	geom_histogram(
		binwidth = 0.5, boundary = 0, closed = "left",
		position = "identity", alpha = 0.6,
		color = "black"
	) +
	# geom_label(
	# 	data = data.frame(
	# 		x = -0.85,
	# 		y = 9,
	# 		label = as.character(latex2exp::TeX(paste0("$U = ", sim_parms$U, "$"))),
	# 		name = "Observed variable"
	# 	),
	# 	aes(x = x, y = y, label = label),
	# 	size = 6,
	# 	parse = TRUE,
	# 	inherit.aes = FALSE
	# ) +
	scale_x_continuous(
		name = "Simulated log titer",
		breaks = seq(-2, 8, 2),
		limits = c(-3.5, 8.5),
		guide = guide_axis(cap = "both"),
		expand = expansion(c(0, 0), c(0.01, 0.01))
	) +
	scale_y_continuous(
		breaks = scales::breaks_pretty(),
		guide = guide_axis(cap = "both"),
		expand = expansion(c(0, 0), c(0, 0.1))
	) +
	scale_fill_brewer(palette = "Dark2", name = NULL) +
	facet_wrap(facets = vars(name)) +
	labs(y = "Count")
```

Of course with this plot, bear in mind that the simulated values of the
observed variable are shown at -1, but this is actually not an accurate
representation of the data, just a convenient one. Perhaps a better
representation of the data would be like this.

```{r}
cens_plot_dat <-
	sim_data |>
	dplyr::mutate(
		yf = factor(
			y,
			levels = c(0, 1),
			labels = c("Not infected", "Infected")
		),
		x_bins = ggplot2::cut_width(
			x,
			width = 0.5,
			closed = "left",
			boundary = 0.5
		)
	) |>
	dplyr::group_by(yf) |>
	dplyr::count(x_bins) |>
	dplyr::ungroup() |>
	# Process the bins into numeric variables
	tidyr::separate(x_bins, into = c("lwr", "upr"), sep = ",") |>
	dplyr::mutate(
		lwr = as.numeric(stringr::str_remove(lwr, "\\[|\\(")),
		upr = as.numeric(stringr::str_remove(upr, "\\]|\\)")),
		cens = factor(dplyr::if_else(lwr <= sim_parms$U, 1, 0))
	)

cens_plot_dat |>
	dplyr::filter(cens == 0) |>
	ggplot() +
	aes(xmin = lwr, xmax = upr, ymin = 0, ymax = n, fill = yf, color = cens) +
	geom_vline(
		xintercept = 0,
		linetype = "dashed",
		color = "black",
		linewidth = 1
	) +
	geom_segment(
		data = cens_plot_dat |> dplyr::filter(cens == 1),
		aes(x = -Inf, xend = sim_parms$LoD, y = n, yend = n, color = yf),
		linewidth = 1,
		show.legend = FALSE,
		arrow = grid::arrow(
			ends = "first",
			length = grid::unit(0.05, "npc"),
			angle = 45
		)
	) +
	geom_rect(
		color = "black",
		alpha = 0.6,
		linewidth = 1
	) +
	scale_x_continuous(
		name = "Simulated log titer",
		breaks = scales::breaks_pretty(),
		limits = c(-3.5, 8.5),
		guide = guide_axis(cap = "both"),
		expand = expansion(c(0, 0), c(0.01, 0.01))
	) +
	scale_y_continuous(
		breaks = scales::breaks_pretty(),
		guide = guide_axis(cap = "both"),
		expand = expansion(c(0, 0), c(0, 0.1))
	) +
	scale_fill_brewer(palette = "Dark2", name = NULL) +
	scale_color_brewer(palette = "Dark2", name = NULL) +
	labs(y = "Count")
```

Here, the arrow tells us a bit more about the censored data. The color of the arrow indicates which outcome group the points belong
to (notice there were no censored data points in the Not Infected group), the
height tells us the number of censored data points, the right endpoint shows
us the limit of detection, and the arrow keeps going to negative infinity,
showing our limited precision about these values. However, this plot is much
less intuitive to understand.

Essentially we can see that our choice of $U$ will strongly affect the
summary statistics of the distribution of infected individuals, which will
in term strongly affect the contrast between the two distributions. So we need
to account for this uncertainty in some way.

Since we have the latent data from our simulation, we can also take a look
at how the censored data might visually impact our logistic regression estimates.

```{r}
interp <-
	tibble::tibble(
		value = seq(-2, 6, 0.1),
		p = inv_logit(sim_parms$alpha + sim_parms$beta * value)
	)

interp2 <-
	dplyr::bind_rows(
		"Latent variable" = interp,
		"Observed variable" = interp,
		.id = "name"
	)

lab1 <- latex2exp::TeX(r"($Pr(y_{i} = 1 \ | \ x_{i})$)")

set.seed(S)
logistic_plot_data <-
	sim_data |>
	dplyr::mutate(
		# Manually add some jitter since ggplot apparently messes it up
		noise = runif(dplyr::n(), -0.05, 0.05),
		yj = y + noise
	) |>
	tidyr::pivot_longer(cols = c(x, x_star)) |>
	dplyr::mutate(
		yf = factor(
			y,
			levels = c(0, 1),
			labels = c("Not infected", "Infected")
		),
		name = factor(
			name,
			levels = c("x_star", "x"),
			labels = c("Latent variable", "Observed variable")
		),
		# Censoring indicator
		cens = (value <= sim_parms$LoD)
	)

logistic_plot_data |>
	ggplot() +
	aes(x = value, color = name, y = yj) +
	geom_vline(
		xintercept = sim_parms$LoD,
		color = "black",
		linetype = "dashed"
	) +
	geom_line(
		data = interp2, aes(y = p), color = "darkgray", linetype = 2, linewidth = 1
	) +
	geom_point(
		data = \(d) dplyr::filter(d, cens == 0 | name == "Latent variable"),
		size = 3,
		alpha = 0.5
	) +
	geom_segment(
		data = \(d) dplyr::filter(d, cens == 1 & name == "Observed variable"),
		aes(x = -Inf, xend = sim_parms$LoD, y = yj, yend = yj, color = name),
		# arrow = grid::arrow(
		# 	length = unit(0.01, "npc"),
		# 	end = "first"
		# ),
		linewidth = 1,
		show.legend = FALSE
	) +
	scale_x_continuous(
		name = "Simulated log titer",
		breaks = scales::breaks_pretty(),
		limits = c(-2.5, 8)
	) +
	scale_y_continuous(
		name = lab1,
		breaks = c(0, 1),
		minor_breaks = seq(0, 1, 0.25)
	) +
	scale_color_brewer(
		palette = "Accent",
		name = NULL,
		guide = guide_legend(override.aes = list(alpha = 1))
	) +
	facet_wrap(facets = vars(name))
```

Again, the horizontal lines for the censored observed variable measurements
indicate that the true latent variables could be anywhere on those lines. Here
we can see that if we were to simply drop the censored data, or treat the
censored values as being equal to the limit of detection, the two groups
would look much more similar to each other. However, if we were to treat the
censored values as being very low, we could make the two groups look arbitarily
different from each other. So understanding the most likely censored values
could be very important to our analysis, depending on the number of censored
observations and their relative influence.

We'll adjust for censoring in our model using the same strategy we discussed
in the previous examples with censored predictors (LINK HERE). Unfortunately
there is no simple model for censored predictors, we basically have to jump
right into writing Stan code. We'll use the same approach as we did before,
assuming a parametric model for $X$ and modeling the joint likelihood of $X$
and the outcome (assuming they are independent).

First, we can examine the Stan code. The model code is based off of the data
generating model above. The main nonintuitive part, is the `target +=`
statement that we need to use to construct the joint likelihood of $X$ and $Y$.

```{r}
one_group_mod_pth <- here::here(base_pth, "Ex4a.stan")
```

::: {.callout-note collapse=true}

## Stan code for model

```{r}
#| class-output: stan
#| echo: false
cat(readLines(one_group_mod_pth), sep = "\n")
```

:::

```{r}
data_list <-
	sim_data |>
	dplyr::mutate(x_l = sim_parms$LoD) |>
	dplyr::select(x, x_l, y) |>
	as.list()

data_list$N <- sim_parms$n

str(data_list)
```

```{r}
mod <- cmdstanr::cmdstan_model(one_group_mod_pth, compile = FALSE)
mod$compile(force_recompile = TRUE, pedantic = TRUE)
```

```{r sample MCMC}
fit <- mod$sample(
	data_list,
	seed = 25452345,
	parallel_chains = 4,
	iter_warmup = 500,
	iter_sampling = 2500,
	show_messages = T
)
```

```{r}
fit$cmdstan_diagnose()
```


```{r}
fit$summary()
```



## Effect of vaccine

Of course, a more interesting question is when we have $k$ different
treatment groups. These groups could be vaccine and placebo, like the example
that motivated this project, or they could be multiple different vaccine
candidates, doses, etc. So we now need to incorporate the effect of the
treatment into the model. However, we know that the treatment will have a
**direct effect on $x$**, the antibody titers, and we can add a **direct effect
on $y$** to represent the combined effect of the vaccine on other facets of the
immune system (e.g. cell-mediated responses) which explain variations in
infection risk that are not due to antibodies.

In this framework, **$x$ becomes a mediator of the relationship between $t$, the
treatment, and $y$**. For simplicity, we model the effect of $t$ on $x$, and the
effect of $t$ and $x$ jointly on $y$, both as linear functions of the
predictors. Specifically, the data generating model is given as follows.

$$
\begin{align*}
y_i &\sim \text{Bernoulli}\left(p_i\right) \\
\mathrm{logit}(p_i) &= \beta_{1, T[i]} + \beta_{2, T[i]} \cdot x^*_i \\
\log\left(x_i^*\right) &\sim \mathrm{Normal}\left(\mu_x, \sigma^2_x\right) \\
\mu_x &= \alpha_{T[i]} \\
x_i &= \begin{cases}
U, & x^*_i < \mathrm{LoD} \\
x^*_i, & x^*_i \geq \mathrm{LoD}
\end{cases} \\
T[i] &= \begin{cases}
1, & \text{individual } i \text{ is in the placebo group} \\
2, & \text{individual } i \text{ is in the vaccine group}
\end{cases}
\end{align*}
$$

Given the generative model, we can simulate data which follow our assumptions.

```{r}
set.seed(341341)
# Some parameters are commented out because I originally had a global
# intercept for mu and for p, but then the intercept parameters are
# nonidentifiable under index coding as written.
sim2_parms <- list(
	n = 116,
	#a0 = 2,
	a1 = c(2.5, 4),
	#b0 = 1.5,
	b1 = c(1.7, 2.2),
	b2 = c(-0.67, -1.37),
	sigma_x = 1.5,
	LoD = 3,
	latent = TRUE
)
sim_two_groups <- function(n, b1, b2, a1, sigma_x, LoD,
													 latent = TRUE) {
	out <- tibble::tibble(
		# Randomly assign each individual to 1 (placebo) or 2 (vaccine)
		t = rbinom(n, size = 1, prob = 0.5) + 1,
		mu = a1[t],
		x_star = rnorm(n, mu, sigma_x),
		x = dplyr::if_else(x_star < LoD, 0.5 * LoD, x_star),
		p = inv_logit(b1[t] + b2[t] * x_star),
		y = rbinom(n, 1, prob = p)
	)
	
	# If the arg 'latent' is specified as anything other than FALSE, return the
	# latent variables that we don't observe. Otherwise return only (X, y).
	if (isFALSE(latent)) {
		out <- out |> dplyr::select(t, x, y)
	}
	
	return(out)
}
sim_data_4b <- do.call(sim_two_groups, sim2_parms)
```

```{r}
tab_dat <-
	sim_data_4b |>
	dplyr::mutate(
		t = factor(
			t,
			levels = c(2, 1),
			labels = c("Vaccine", "Placebo")
		),
		y = factor(
			y,
			levels = c(1, 0),
			labels = c("Infected", "Not infected")
		)
	)
tab_dat |>
	gtsummary::tbl_cross(
		row = t, col = y,
		label = list(t ~ "Treatment", y ~ "Outcome")
	)
```

Because the data are from a (hypothetical) clinical trial, the typical
epidemiological approach to data analysis, if we do not care about the effect
of the mediator $x$ would be to calculate the risk ratio.

```{r}
tab <- table(tab_dat$t, tab_dat$y, dnn = c("Treatment", "Outcome"))
epiR_out <- epiR::epi.2by2(
	tab,
	method = "cohort.count"
)
epiR_out
```

```{r}
# This one takes the variables in the opposite direction so easier to do it
# this way
epiDisplay::csi(
	caseexp = tab[[1]],
	controlex = tab[[3]],
	casenonex = tab[[2]],
	controlnonex = tab[[4]]
)
```

So if we didn't care about the effect of $x$ at all, we would conclude that the
vaccine appears to be protective with a RR of $`r
round(epiR_out$massoc.summary[[1, 2]], 2)`$ and a 95% CI of $\left(`r
round(epiR_out$massoc.summary[[1, 3]], 2) - round(epiR_out$massoc.summary[[1,
4]], 2)`\right)$. **Note that this analysis is marginal to the censored $x_i$
values, and since the data generating process for $y_i$ relies on the latent
$x^*_i$ values, this analysis should not be biased by the censoring process.**

However, in our study we specifically want to know how
much of the lower risk is explained by the antibody titer, and how much is not.
This analysis is more complicated, and requires us to use a regression model.
Fortunately we know the data generating process, so writing the Stan code
for an accurate model is not too hard.

<!-- NEED TO ADD HIDING CONTAINER and debug
````{.stan, include = "Ex4b.stan"}

```
--->

```{r}
mod_pth <- here::here(pth_base, "Ex4b.stan")
mod4b <- cmdstanr::cmdstan_model(mod_pth, compile = F)
mod4b$compile(pedantic = TRUE, force_recompile = TRUE)
```

```{r}
mod4b_data <- sim_data_4b |>
	dplyr::mutate(x_l = sim2_parms$LoD, t = as.integer(t)) |>
	dplyr::select(t, y, x, x_l) |>
	as.list()

mod4b_data <- c(
	"N" = nrow(sim_data_4b),
	"k" = as.integer(max(mod4b_data$t)),
	mod4b_data
)
str(mod4b_data)
paste0(
	"Naruto checked the data and he says:\n",
	round(mean(mod4b_data$x <= mod4b_data$x_l), 4) * 100,
	"% of x values are below the LoD!\nBelieve it!"
) |> cat()
```

```{r}
fit4b <- mod4b$sample(
	mod4b_data,
	seed = 5234521,
	parallel_chains = 4,
	iter_warmup = 500,
	iter_sampling = 2500,
	show_messages = T
)
```

```{r}
fit4b$summary()
str(sim2_parms)
```

```{r}
fit_summary <- fit4b$summary() |>
	dplyr::select(variable, median, q5, q95) |>
	dplyr::filter(variable != "lp__") |>
	dplyr::mutate(
		truth = c(
			#sim2_parms$a0,
			sim2_parms$a1[[1]],
			sim2_parms$a1[[2]],
			sim2_parms$sigma_x,
			#sim2_parms$b0,
			sim2_parms$b1[[1]],
			sim2_parms$b1[[2]],
			sim2_parms$b2[[1]],
			sim2_parms$b2[[2]]
		)
	)

po <-
	ggplot(fit_summary) +
	aes(x = variable, y = median, ymin = q5, ymax = q95) +
	geom_hline(yintercept = 0, linetype = "dashed", color = "gray") +
	geom_pointrange() +
	geom_point(aes(y = truth), shape = 4, color = "red", size = 3, stroke = 1) +
	labs(
		x = NULL,
		y = "Parameter value",
		title = "Model-estimated median with 95% CI; x marks true simulation value",
		subtitle = "Estimated with observed (censored) values with correction"
	)
```

## Model if x was not censored

```{r}
mod4b_data_l <- sim_data_4b |>
	dplyr::mutate(x_l = -9999, t = as.integer(t)) |>
	dplyr::select(t, y, x = x_star, x_l) |>
	as.list()

mod4b_data_l <- c(
	"N" = nrow(sim_data_4b),
	"k" = as.integer(max(mod4b_data_l$t)),
	mod4b_data_l
)
str(mod4b_data_l)
```

```{r}
fit4b_l <- mod4b$sample(
	mod4b_data_l,
	seed = 5234521,
	parallel_chains = 4,
	iter_warmup = 500,
	iter_sampling = 2500,
	show_messages = T
)
```

```{r}
fit4b_l$summary()
str(sim2_parms)
```

```{r}
fit_summary_l <- fit4b_l$summary() |>
	dplyr::select(variable, median, q5, q95) |>
	dplyr::filter(variable != "lp__") |>
	dplyr::mutate(
		truth = c(
			#sim2_parms$a0,
			sim2_parms$a1[[1]],
			sim2_parms$a1[[2]],
			sim2_parms$sigma_x,
			#sim2_parms$b0,
			sim2_parms$b1[[1]],
			sim2_parms$b1[[2]],
			sim2_parms$b2[[1]],
			sim2_parms$b2[[2]]
		)
	)

pl <-
	ggplot(fit_summary_l) +
	aes(x = variable, y = median, ymin = q5, ymax = q95) +
	geom_hline(yintercept = 0, linetype = "dashed", color = "gray") +
	geom_pointrange() +
	geom_point(aes(y = truth), shape = 4, color = "red", size = 3, stroke = 1) +
	labs(
		x = NULL,
		y = "Parameter value",
		title = "Model-estimated median with 95% CI; x marks true simulation value",
		subtitle = "Estimated using true latent values"
	)
```

## Do it the naive way

```{r}
mod4b_data_n <- sim_data_4b |>
	dplyr::mutate(x_l = -9999, t = as.integer(t)) |>
	dplyr::select(t, y, x = x, x_l) |>
	as.list()

mod4b_data_n <- c(
	"N" = nrow(sim_data_4b),
	"k" = as.integer(max(mod4b_data_n$t)),
	mod4b_data_n
)
str(mod4b_data_n)
```

```{r}
fit4b_n <- mod4b$sample(
	mod4b_data_n,
	seed = 873215,
	parallel_chains = 4,
	iter_warmup = 500,
	iter_sampling = 2500,
	show_messages = T
)
```

```{r}
fit4b_n$summary()
str(sim2_parms)
```

```{r}
fit_summary_n <- fit4b_n$summary() |>
	dplyr::select(variable, median, q5, q95) |>
	dplyr::filter(variable != "lp__") |>
	dplyr::mutate(
		truth = c(
			#sim2_parms$a0,
			sim2_parms$a1[[1]],
			sim2_parms$a1[[2]],
			sim2_parms$sigma_x,
			#sim2_parms$b0,
			sim2_parms$b1[[1]],
			sim2_parms$b1[[2]],
			sim2_parms$b2[[1]],
			sim2_parms$b2[[2]]
		)
	)

pn <-
	ggplot(fit_summary_n) +
	aes(x = variable, y = median, ymin = q5, ymax = q95) +
	geom_hline(yintercept = 0, linetype = "dashed", color = "gray") +
	geom_pointrange() +
	geom_point(aes(y = truth), shape = 4, color = "red", size = 3, stroke = 1) +
	labs(
		x = NULL,
		y = "Parameter value",
		title = "Model-estimated median with 95% CI; x marks true simulation value",
		subtitle = "Estimated using censored values without censoring correction"
	)
```

```{r}
po / pl / pn
```

```{r}
all_fits <-
	dplyr::bind_rows(
		"corrected" = fit_summary,
		"latent" = fit_summary_l,
		"naive" = fit_summary_n,
		.id = "model"
	)

all_fits |>
	ggplot() +
	aes(
		x = variable, y = median, ymin = q5, ymax = q95,
		color = model
	) +
	geom_hline(yintercept = 0, linetype = "dashed", color = "gray") +
	geom_crossbar(
		aes(y = truth, ymin = truth, ymax = truth),
		width = 0.5,
		color = "black",
		fatten = 0.1
	) +
	geom_pointrange(position = position_dodge2(width = 0.3)) +
	scale_color_brewer(palette = "Dark2") +
	labs(
		x = NULL,
		y = "Parameter value",
		title = "Model-estimated median with 95% CI; line marks true value"
	)
```


## Model exploration

**these curves are implied by the model and parameters, not by the simulated
data**
```{r}
x_vec <- seq(-6, 12, 0.01)
r1 <- sapply(x_vec, \(x) inv_logit(1.5 + 0.2 - 0.67 * x))
r2 <- sapply(x_vec, \(x) inv_logit(1.5 + 0.7 - 1.37 * x))

layout(matrix(c(1, 2, 3, 3), ncol = 2, byrow = TRUE))
plot(x_vec, r2 - r1, ylab = "risk difference", type = "l", xlab = "")
abline(h = 0, lty = 2)
plot(x_vec, r2 / r1, ylab = "risk ratio", type = "l", xlab = "")
abline(h = 1, lty = 2)
lab2 <- latex2exp::TeX(r"($Pr(y_{i} = 1 \ | \ x_{i}, T_{i})$)")
plot(
	NULL, NULL,
	ylim = c(0, 1),
	xlim = c(-6, 12),
	yaxs = "i",
	xaxs = "i",
	xlab = "Simulated log titer",
	ylab = lab2
)
lines(x_vec, r1, lty = 2, lwd = 1.5) # placebo
lines(x_vec, r2, lty = 1, lwd = 1.5) # vaccine
# IDK what's wrong with the legend, seems it doesn't like layout.
# switch to ggplot to fix
#legend(x = 9, y = 0.8, c('Unexposed', 'Exposed'), lty = c(2, 1), lwd = 2)
```

```{r}
x_dens <-
	tibble::tibble(
		Latent = x_vec,
		Observed = dplyr::if_else(
			x_vec < sim2_parms$LoD,
			sim2_parms$LoD,
			x_vec
		),
		Placebo = sim2_parms$a1[1],
		Vaccine = sim2_parms$a1[2]
	) |>
	tidyr::pivot_longer(
		cols = c(Placebo, Vaccine),
		names_to = "t",
		values_to = "mu"
	) |>
	tidyr::pivot_longer(
		cols = c(Latent, Observed),
		names_to = "o",
		values_to = "x"
	) |>
	dplyr::mutate(
		d = dplyr::if_else(
			o == "Latent",
			dnorm(x, mean = mu, sd = sim2_parms$sigma_x),
			crch::dcnorm(
				x, mean = mu, sd = sim2_parms$sigma_x,
				left = sim2_parms$LoD, right = Inf
			)
		)
	)

anno_df <-
	x_dens[1:4, ] |>
	dplyr::filter(o == "Observed")

x_dens |>
	ggplot() +
	aes(x = x, y = d, linetype = t, group = t) +
	geom_vline(
		xintercept = sim2_parms$LoD,
		linetype = 1, linewidth = 1, color = "gray"
	) +
	geom_line(linewidth = 1.5) +
	geom_point(
		data = anno_df,
		size = 2,
		stroke = 2,
		shape = 21,
		color = "black",
		fill = "darkgray"
	) +
	facet_grid(vars(o), vars(t)) +
	scale_linetype_discrete(name = NULL) +
	scale_x_continuous(breaks = scales::breaks_pretty()) +
	scale_y_continuous(breaks = scales::breaks_pretty()) +
	labs(
		x = "Simulated log titer",
		y = "Implied probability density"
	) +
	#coord_cartesian(expand = FALSE, ylim = c(-0.01, 0.28)) +
	theme(axis.text.y = element_text(size = 10))
```

## Try gamma dist. for x on non-logged scale?

## Do we want to work out a hierarchical model?

## What if $X$ and $Y$ are not independent

Can try a copula

## What if we mis-specify the distribution of $X$?

Try the normal model on gamma and the gamma model on normal

<!-- END OF FILE -->

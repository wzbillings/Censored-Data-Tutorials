# One censored predictor

```{r setup}
# Need to load all of cmdstanr or some things act weird
library(cmdstanr)

# ggplot2 theme setup
library(ggplot2)
ggplot2::theme_set(hgp::theme_ms())

# Load utility functions
source(here::here("utils.R"))

# Set up a variable with the base path for this document
pth_base <- here::here("examples", "simple-censored-predictor")

# Set a constant value for pRNG seed
S <- 370
```

Now we'll consider the case where our outcome is perfectly observed, but we have
a single predictor value with a limit of detection. Most commonly used models
consider predictor values to be completely observed, exact measurements without
error, which makes dealing with censoring of a predictor more complicated than
dealing with censoring of an outcome. In order to address censoring in a
predictor, we also have to assume the predictor values are, in some way,
unknown, like we do for the outcomes. Before we discuss methods for dealing
with a censored predictor, let's take a look at some simulated data and the
associated data generating process.

## Data-Generating Process

The data will discuss consist of $n$ observations of a predictor variable, $x$,
and an outcome variable, $y$. To make this example simple, we'll assume there is
a linear relationship between $x$ and $y$. So the data generating process (DGP) 
for the outcome, $y_i, \ i = \{1, 2, \ldots, n\}$, is
$$
\begin{align*}
y_i &\sim \mathrm{Normal}\left(\mu_i, \sigma^2\right) \\
\mu_i &= \beta_0 + \beta_1 x_i^*
\end{align*}
$$
where $x_i^*$ represents the true value of our predictor. Importantly, for
the predictor, $x$, to be censored, there also has to be a data generating
process for $x$. If we conduct a controlled experiment where we determine the
values for $x$, it doesn't make sense for $x$ to be censored (which is why
this case is discussed less often than the case of a censored outcome). But if
we are conducting an observational study, where we expect $x$ to influence $y$,
but we cannot directly manipulate the value of $x$, then it makes sense for
$x$ to potentially be censored. Like with a censored outcome, we can discuss
the DGP for the *latent* or true $x_i^*$ values, and the observation process
which generates our imperfect observation $x_i$. Of course, the most simple
example would be a Normal distribution[^1]:
$$
x_i^* \sim \text{Normal}\left(\lambda, \tau^2\right).
$$

[^1]: There's actually a statistical issue with this Normal/Normal model: it's
not fully identifiable without extra constraints. See the [errors-in-variables
wikipedia page](https://en.wikipedia.org/wiki/Errors-in-variables_models) for a
bit more info.

This is the part where we'll just say you can put whichever distribution here
as well -- don't worry, we'll do another non-normal example after this. Now
that we have a DGP for the latent $X^*$ values, we need to specify our
observation model. For a simple case of censoring, this could include a lower
limit of detection (LoD), an upper LoD, or both. For example, with a lower LoD,
the observation model might look like this:

$$
x_i = \begin{cases}
x_{\min}, & x_i^* \leq x_{\min} \\
x_i^*, & x_i^* > x_{\min}
\end{cases}; \quad x_{\min} \in \mathbb{R}.
$$

Here, $x_{\min}$ is a constant value representing a lower limit of detection --
if the latent value $x_i^*$ is less than the threshold represented by $x_{\min}$,
we just observe $x_{\min}$. If the true value is greater than this threshold,
we observe the true value. This is not a unique observation process -- we can,
in principle, write down any value for the censored observations. To avoid
confusion, we should also define an indicator variable for whether the $i$th
observation is censored:
$$
c_i = I\left( x_i^* \leq x_{\min} \right) =
\begin{cases}
1, & x_i^* \leq x_{\min} \\
0, & \text{otherwise}
\end{cases}.
$$
Typically, we can observe all values of $c_i$, and we assume that *these*
are measured perfectly (although this is not strictly necessary, as we could
incorporate measurement error and thus misclassification models into our
observation process, but we neglect those here for the sack of simplicity). If
you receive a data set you know a variable is censored, but there is no way to
determine which values are censored due to improper coding and recording, there
is not much you can do to resolve the situation. So it is typically best to
record censored values using some value **which could not have been observed if
the observation were not censored**. Do not worry if this description is
abstract -- next we will consider a concrete example which will hopefully help
to make these concepts concrete.

For reference, we can write down the entire data-generating process all
together. Note that from this DGP, we observe $(x_i, c_i, y_i); \ i = 1, \ldots, n$.

$$
\begin{align*}
y_i &\sim \mathrm{Normal}\left(\mu_i, \sigma^2\right) \\
\mu_i &= \beta_0 + \beta_1 x_i^* \\
x_i^* &\sim \text{Normal}\left(\lambda, \tau^2\right) \\
x_i &= \begin{cases}
x_{\min}, & x_i^* \leq x_{\min} \\
x_i^*, & x_i^* > x_{\min}
\end{cases}; \\
c_i &= I\left( x_i^* \leq x_{\min} \right)
\end{align*}
$$
Here, $\sigma$ and $\tau$ are positive real numbers, and the following are
real-valued constants: $\beta_0$, $\beta_1$, $x_{\min}$, and $\lambda$.

## Weighing cats

Now that we've gone through the basics of the data-generating process, let's
set up the DGP for an example data set. Once we've worked out the DGP, we'll
take a look at some simulated data from this example. Then we'll finally
discuss methods for dealing with censored predictor data.

Suppose we're conducting a study on cholesterol in cats, and we want to know
whether elevated cholesterol levels are associated with cat weight --
presumably, heavier cats have higher overall cholesterol values. For simplicity,
we limit our study to adult male American shorthair cats (we can recruit other
types of cats after we finish this pilot study). According to
[this article](https://web.archive.org/web/20240305033813/https://www.thesprucepets.com/american-shorthair-cat-breed-profile-4774399),
the normal weight for such a cat is from 11 -- 15 pounds. So, we'll take 13 lbs.
as the average weight of a cat, and 2 lbs. as the standard deviation.So, letting $w_i^*$ represent the true weight of the $i$th cat, we would write
$$w_i^* \sim \mathrm{Normal} \left(13, 2^2\right).$$

Now, the problem is that we do not have a very good scale -- our scale is
accurate to the tenth of a pound, but the highest value it can measure is 14
lbs[^Our scale could also have a lower bound, but in this case it's probably so low that we would never get any left-censored observations.]. In terms of the DGP, we would say that
$$w_{\max} = 14.$$

Using that information, we can then write out the observation model for the
weight data.
$$
w_i = \begin{cases}
w_{\max}, & w_{\max} \leq w_i^*  \\
w_i^*, & w_i^* < w_{\max}
\end{cases}.
$$
This is not much more complicated than the abstract example we wrote out before
that only had a lower LoD, in fact it's easily taken care of in the same
likelihood step. Now, we'll also need to set up an indicator variable, which
we call $c_i$, that tells us if our weight values are censored or not.

$$
c_i = \begin{cases}
1, & w_i \geq w_{\max} \\
0, & \text{otherwise}
\end{cases}.
$$

Next, we need to pick a distribution for our outcome. Since many biological
concentration values often follow [Gamma distributions](https://en.wikipedia.org/wiki/Gamma_distribution), let's use
that for our cholesterol levels [^This will also allow us to avoid the
identifiability issue we briefly mentioned.]. Based on
[this article](https://web.archive.org/web/20240305035325/https://cats.com/high-cholesterol-in-cats)
(I have no idea how accurate it is, if at all, just like the previous one),
the normal amount of cholesterol for a cat is 1.8 -- 3.9 mMol/liter. So, we just
need to choose Gamma distribution parameters.

::: {.callout-note icon=false collapse=true appearance="simple"}

### Gamma distribution parametrization {.unnumbered}
There are at least three common reparametrizations of the Gamma parametrization.
[Stan](https://mc-stan.org/docs/functions-reference/gamma-distribution.html)
implements the standard "shape-rate" parametrization, which is most commonly
used by statisticians. In the `rethinking` package, Richard McElreath implements
a "mean-scale" parametrization which uses the substitution
$\alpha = \mu / \beta$. **However**, in a GLM context, the most frequently
used parametrization is the "shape-mean" parametrization[^See, e.g. McCullagh and Nelder's *Generalized Linear Models*, 2nd edition; or Agresti's *Foundations of Generalized Linear Models*.]. 

Beginning with the parametrization made in the Stan guide, we make the
substitutions $\alpha = k$ and $\beta = \frac{k}{\mu}$.
By making those substitutions in the density, we can show that
$$E(y) = \mu \quad \text{and} \quad \mathrm{Var}(y) = \frac{\mu^2}{k}.$$

When we specify $\mu = f(X)$ in the context of a linear model, we must then
invert the transformation, and when we invoke the gamma distribution in Stan,
we would write
$$y \sim \text{Gamma}\left(k, \frac{k}{\mu} \right).$$

:::

If we treat the range the same as we did previously, we can estimate that the
overall average is around 2.85, with a spread of 1.05. That seems a little high,
so let's assume they gave us a two standard deviation range, and cut it in half,
and we'll round that down to $0.5$, which is probably good enough for government
work.
(Of course if you want to simulate the data, you can make whatever arbitrary
assumptions like this that you prefer instead.)

So, we would write the distribution for our cholesterol values, which we'll
call $y$, as
$$
y_i \sim \text{Gamma}\left(k, \frac{k}{\mu_i}\right).
$$
To relate this to the weight values, we would then write out our linear model
for $\mu_i$, the mean, as

$$
\mu_i = \alpha + \beta \cdot w^*_i.
$$
Choosing values of $\alpha$, $\beta$, and $k$, that make sense together and
match the ranges we expect is kind of hard -- for the purposes of this
simulation, I just messed around until I got values that I liked. Note that
because the variance depends on the mean, we don't have a separate parameter
for the residual variance. Instead, $\alpha$ and $\beta$ affect the
residual variance (as does the distribution of $w_i$), and the parameter
$k$ is independent of the mean but also has an effect on the variance. So
for this example, I choose the simulation parameters $k=18$, $\alpha = 0.75$,
and $\beta = 0.16$.

```{r data generation parameters}
# List of data generating parameters / simulation parameters
data_gen_parms <- list(
	# Number of observations to generate
	n = 154,
	# Set a static constant value for the lower limit of detection (LoD)
	ulod = 14,
	# Linear model intercept
	alpha = 0.75,
	# Linear model slope
	beta = 0.16,
	# Linear model residual variance
	k = 18,
	# Mean of normally distributed x values
	w_mu = 13,
	# SD of normally distributed x values
	w_sd = 2
)
```

Now we need to simulate the data. I randomly decided that we should have 154
cats in our stduy sample.

```{r}
generate_cat_weight_data <- function(
		n = 1000, ulod = 2, alpha = 1, beta = 2, k = 5, w_mu = 5, w_sd = 3,
		seed = S
) {
	set.seed(S)
	
	l <- tibble::tibble(
		w_star = rnorm(n, w_mu, w_sd),
		w = ifelse(w_star >= ulod, ulod, w_star),
		c = ifelse(w_star >= ulod, 1, 0),
		mu = alpha + beta * w_star,
		y = rgamma(n, shape = k, rate = k / mu)
	)
	
	o <- dplyr::select(l, w, y, c)
	
	out <- list("latent" = l, "observed" = o)
	return(out)
}
dat <- do.call(generate_cat_weight_data, data_gen_parms)
dat_latent <- dat$latent
dat_observed <- dat$observed

dplyr::glimpse(dat_latent)
```

Now let's take a quick look at the latent data so we can visualize the effect
of censoring the predictor.

```{r}
dat_latent |>
	ggplot() +
	geom_vline(
		xintercept = data_gen_parms$ulod,
		linetype = "dashed",
		color = "gray"
	) +
	geom_segment(
		aes(
			x = w_star, xend = w,
			y = y, yend = y
		),
		color = "gray"
	) +
	geom_point(aes(x = w_star, y = y), color = "gray", size = 2) +
	geom_point(aes(x = w, y = y), color = "black", size = 2) +
	labs(x = "Weight", y = "Cholesterol")
```

Here the gray points show the true latent values of the censored points, and
the black points show what we actually observed. You can see that we
obviously observe a much smaller range of data when censoring happens. If we
had the latent variables in real life, we could use a Gamma family GLM to
estimate the coefficients of the linear model, like this.

```{r}
latent_gamma_glm <- glm(
	y ~ w_star,
	family = Gamma(link = "identity"),
	data = dat_latent
)
broom::tidy(latent_gamma_glm, conf.int = TRUE)
```

Note that the dispersion estimate is an estimate of $1/k$. We can also get a
slightly improved estimate of $k$ using a helper function from the `MASS`
package. (The function performs another round of maximum likelihood estimation,
the actual estimate from `glm()` is the MLE of the coefficients but not of the
dispersion.)

```{r}
MASS::gamma.shape(latent_gamma_glm)
```

The estimates are affected by sampling error, perhaps moreso than we would
expect from a Gaussian regression model. But overall they're fairly close,
and our CI for the coefficients includes the true values. So, the natural
next question is what happens when we fit the model with the actual observed
data that's been censored? (I always call this the "naive" model, because we
are naively hoping for a model that breaks our assumptions to work.)

```{r}
naive_gamma_glm <- glm(
	y ~ w,
	family = Gamma(link = "identity"),
	data = dat_observed
)
broom::tidy(naive_gamma_glm, conf.int = TRUE)
```

Well, in this case, we can see that the estimates are actually not too
different. The are a bit off and the standard errors are larger, but we could
probably get away with using these same estimates, we just seem to have a less
precise answer.

## More censoring!

Of course, if ignoring the problem didn't make a difference, we would want to
just ignore it, right? But let's see what happens when we increase the amount
of data that are censored. So this time, let's say our scale has a maximum of
12 lbs[^A good question to ask at this point is whether we should actually be doing this study if we can't get better measures. But some immunological or environmental studies actually have more than 50% censored or missing data, and sometimes the question is so important that we really want to get the most out of the data we have.]. So first let's rerun the simulation.

```{r}
data_gen_parms_2 <- data_gen_parms
data_gen_parms_2$n <- 10000
data_gen_parms_2$ulod <- 13
dat2 <- do.call(generate_cat_weight_data, data_gen_parms_2)
dat2_latent <- dat2$latent
dat2_observed <- dat2$observed

dplyr::glimpse(dat2_latent)
```

If we plot these new simulated data, we can see that many more data points are
censored that before, it looks like over half of them.

```{r}
dat2_latent |>
	ggplot() +
	# geom_vline(
	# 	xintercept = data_gen_parms_2$ulod,
	# 	linetype = "dashed",
	# 	color = "gray"
	# ) +
	# geom_segment(
	# 	aes(
	# 		x = w_star, xend = w,
	# 		y = y, yend = y
	# 	),
	# 	color = "gray"
	# ) +
	geom_point(aes(x = w_star, y = y), color = "black", size = 2) +
	#geom_point(aes(x = w, y = y), color = "black", size = 2) +
	labs(x = "Weight", y = "Cholesterol")
```

Now let's see what happens when we fit a naive model.

```{r}
naive_gamma_glm_2 <- glm(
	y ~ w,
	family = Gamma(link = "identity"),
	data = dat2_observed
)
broom::tidy(naive_gamma_glm_2, conf.int = TRUE)
```

Now we can see that the estimates are much worse. Interestingly, the CI for
the slope still contains the true estimate, but the whole interval is moved
upwards, and is wider. The intercept also basically can't be estimted at all
using this model, the model predicts that it could pretty much be anything,
which isn't ideal. So let's see if we can fix things.

## Model for censored predictors

Let's first write out the entire data generating process in one place.

$$
\begin{aligned}
y_i &\sim \text{Gamma}\left(k, \frac{k}{\mu_i}\right) \\
\mu_i &= \alpha + \beta \cdot w^*_i \\
w_i^* &\sim \mathrm{Normal} \left(\mu_w, \sigma_w^2 \right) \\
w_i &= \begin{cases}
w_{\max}, & w_{\max} \leq w_i^*  \\
w_i^*, & w_i^* < w_{\max}
\end{cases}
\end{aligned}
$$

Here, we assume $w_{\max} = 12$ is a known constant. In future tutorials, we'll
discuss what to do if this isn't a known constant, but in most situations
that arise in a lab study, we do know the censoring limits.

Now, the unfortunate thing about censored predictors like this, is that there
are (to my knowledge) no out-of-the-box models that can adjust the likelihood.
Most frequentist methods assume that the $w_i$ predictor variables are
**known constants** which have no intrinsic error. Of course this is rarely
true (outside of a specific type of experimental setup), and there are
[errors-in-variables
models](https://en.wikipedia.org/wiki/Errors-in-variables_models) which can help
to address this. But I'm not aware of any errors-in-variables implementations
that allow for arbitrary and censored predictor distributions.

So, we'll use Stan to fit a model, and we'll use an approach called **joint
modeling**. Instead of optimizing the likelihood of $y$ conditional on $x$,
we'll optimize the joint likelihood of $x$ and $y$, which is fairly easy to do
in Stan. The crucial assumption we will make is that the marginal distributions
of $x$ and $y$ are conditionally independent. That means that we can multiply
the likelihood of $x$ and the likelihood of $y$ conditional on $x$ to get the
joint likelihood of $x$ and $y$. This is not always true, and there are some
more advanced approaches like specifying the functional form of the joint
distribution for $x$ and $y$, or [using a copula
function](https://onlinelibrary.wiley.com/doi/10.1002/sim.8995). But I think
this simplifying independance assumption is not too different from the
assumptions we normally make when we do regression, and it's a step above
assuming the independant variables have no error.

Once we've specified that we're optimizing the joint likelihood of $x$ and $y$,
and we're making an independence assumption to construct that likelihood, **we
can adjust for censoring in the predictors using the same integration method
we used for the outcome.**

This type of model is implemented in the following Stan code. To fit a Stan
model, we'll also need to specify priors, and I decided to use the same generic
Student's (Half) $t$ priors that I discussed in the previous section.

::: {.callout-note icon=false collapse=true appearance="simple"}
##### Model code {.unnumbered}

`r here::here(pth_base, "censored-predictor.stan")`

:::

As with last time, first we need to set up a data list that matches what the
Stan code expects in the `data` block.

```{r set up stan data}
stan_data <- list(
	n = nrow(dat2_observed),
	y = dat2_observed$y,
	w = dat2_latent$w_star,
	c = dat2_observed$c,
	ulod = data_gen_parms_2$ulod
)
str(stan_data, 1)
```

Next we'll load and compile the program.

```{r load stan model}
#| message: true
mod_path <- here::here(pth_base, "censored-predictor.stan")
stan_mod <- cmdstanr::cmdstan_model(mod_path, compile = FALSE)
stan_mod$compile(pedantic = TRUE, force_recompile = TRUE)
```

Now we can do the fun part of running the sampler.

```{r sample stan model}
#| message: false
fit <- stan_mod$sample(
	data = stan_data,
	seed = S,
	parallel_chains = 4,
	chains = 4,
	iter_warmup = 1000,
	iter_sampling = 4000
)
```

```{r}
fit$summary() |> print(n = Inf)
```

## The other method (Bjorn method)

```{r}
mod_pth <- here::here(pth_base, 'Ex1b.stan')
mod2 <- cmdstanr::cmdstan_model(stan_file = mod_pth)
```

```{r}
dat2 <- list()
dat2$y <- df_stan$y
dat2$x <- df_stan$x
dat2$x_cens <- df_stan$cens
dat2$N <- length(dat2$y)
dat2$DL <- lod
```

```{r}
fit2 <- mod2$sample(dat2, seed = 100, parallel_chains = 4)
```

```{r}
fit2$summary() |>
	dplyr::filter(!startsWith(variable, "x")) |>
	print(n = Inf)
```

```{r}
post <- posterior::as_draws_array(fit2)
```


<!-- END OF FILE -->
